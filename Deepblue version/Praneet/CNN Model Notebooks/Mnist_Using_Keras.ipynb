{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import os\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import SGD,RMSprop, adadelta, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'D:\\\\OCR14PDBS3\\\\CNN Model Notebooks./mnist_png/training'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-15dbfb851ef6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mPATH\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdata_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPATH\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'./mnist_png/training'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdata_Dir_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_Dir_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'D:\\\\OCR14PDBS3\\\\CNN Model Notebooks./mnist_png/training'"
     ]
    }
   ],
   "source": [
    "PATH = os.getcwd()\n",
    "data_path = PATH + './mnist_png/training'\n",
    "data_Dir_list = os.listdir(data_path)\n",
    "print(data_Dir_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_row = 28\n",
    "img_col = 28\n",
    "num_channel = 1\n",
    "epoch = 20\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6903, 14780, 21770, 28911, 35735, 42048, 48924, 56217, 63042, 70000]\n"
     ]
    }
   ],
   "source": [
    "img_data_list = []\n",
    "images = []\n",
    "i = 0\n",
    "\n",
    "for dataset in data_Dir_list:\n",
    "    img_list = os.listdir(data_path + '/' + dataset)\n",
    "    for img in img_list:\n",
    "        i = i+1\n",
    "        ip_img = cv2.imread(data_path + '/' + dataset + '/' + img)\n",
    "        ip_img = cv2.cvtColor(ip_img, cv2.COLOR_BGR2GRAY)\n",
    "        ip_img = cv2.resize(ip_img, (img_row,img_col))\n",
    "        img_data_list.append(ip_img)\n",
    "    images.append(i)\n",
    "\n",
    "print(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_data = np.array(img_data_list)\n",
    "img_data = img_data.astype('float32')\n",
    "img_data /= 255\n",
    "img_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Praneet\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:2: DeprecationWarning: Both axis > a.ndim and axis < -a.ndim - 1 are deprecated and will raise an AxisError in the future.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(70000, 28, 28, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Expand dimesnsions\n",
    "img_data= np.expand_dims(img_data, axis=4)\n",
    "img_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Preprocessing\n",
    "n_samples = img_data.shape[0]\n",
    "labels = np.ones((n_samples,), dtype='int64')\n",
    "\n",
    "label_dictionary = {0:'0', 1:'1', 2:'2', 3:'3', 4:'4', 5:'5', 6:'6', 7:'7', 8:'8', 9:'9'}\n",
    "\n",
    "labels[:images[0]] = 0\n",
    "labels[images[0]:images[1]] = 1\n",
    "labels[images[1]:images[2]] = 2\n",
    "labels[images[2]:images[3]] = 3\n",
    "labels[images[3]:images[4]] = 4\n",
    "labels[images[4]:images[5]] = 5\n",
    "labels[images[5]:images[6]] = 6\n",
    "labels[images[6]:images[7]] = 7\n",
    "labels[images[7]:images[8]] = 8\n",
    "labels[images[8]:images[9]] = 9\n",
    "\n",
    "#One-Hot encoded format\n",
    "Y = to_categorical(labels, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-b47b0dfbc3d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m#Shuffle data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[1;31m#Split Dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'img_data' is not defined"
     ]
    }
   ],
   "source": [
    "#Shuffle data\n",
    "from sklearn.utils import shuffle\n",
    "x, y = shuffle(img_data, Y, random_state=2)\n",
    "#Split Dataset\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size=0.25, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will build our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 12, 12, 64)        8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 5, 5, 128)         32896     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 1, 1, 256)         131328    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 272,778\n",
      "Trainable params: 272,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (2,2), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(128, (2,2), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(256, (2,2), activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Callbacks Tensorboard\n",
    "from keras.callbacks import TensorBoard\n",
    "tbcallback = TensorBoard(log_dir='./Graph/', histogram_freq=1, write_graph=True, write_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 52500 samples, validate on 17500 samples\n",
      "Epoch 1/20\n",
      "52500/52500 [==============================] - 95s 2ms/step - loss: 0.4471 - acc: 0.8553 - val_loss: 0.0736 - val_acc: 0.9779\n",
      "Epoch 2/20\n",
      "52500/52500 [==============================] - 98s 2ms/step - loss: 0.1502 - acc: 0.9585 - val_loss: 0.0609 - val_acc: 0.9819\n",
      "Epoch 3/20\n",
      "52500/52500 [==============================] - 107s 2ms/step - loss: 0.1205 - acc: 0.9669 - val_loss: 0.0495 - val_acc: 0.9853\n",
      "Epoch 4/20\n",
      "52500/52500 [==============================] - 95s 2ms/step - loss: 0.1006 - acc: 0.9723 - val_loss: 0.0444 - val_acc: 0.9863\n",
      "Epoch 5/20\n",
      "52500/52500 [==============================] - 94s 2ms/step - loss: 0.0942 - acc: 0.9735 - val_loss: 0.0415 - val_acc: 0.9877\n",
      "Epoch 6/20\n",
      "52500/52500 [==============================] - 94s 2ms/step - loss: 0.0866 - acc: 0.9764 - val_loss: 0.0396 - val_acc: 0.9890\n",
      "Epoch 7/20\n",
      "52500/52500 [==============================] - 95s 2ms/step - loss: 0.0810 - acc: 0.9774 - val_loss: 0.0431 - val_acc: 0.9892\n",
      "Epoch 8/20\n",
      "52500/52500 [==============================] - 94s 2ms/step - loss: 0.0742 - acc: 0.9798 - val_loss: 0.0351 - val_acc: 0.9889\n",
      "Epoch 9/20\n",
      "52500/52500 [==============================] - 94s 2ms/step - loss: 0.0726 - acc: 0.9802 - val_loss: 0.0341 - val_acc: 0.9902\n",
      "Epoch 10/20\n",
      "52500/52500 [==============================] - 94s 2ms/step - loss: 0.0715 - acc: 0.9813 - val_loss: 0.0480 - val_acc: 0.9875\n",
      "Epoch 11/20\n",
      "52500/52500 [==============================] - 94s 2ms/step - loss: 0.0697 - acc: 0.9816 - val_loss: 0.0370 - val_acc: 0.9899\n",
      "Epoch 12/20\n",
      "52500/52500 [==============================] - 95s 2ms/step - loss: 0.0643 - acc: 0.9821 - val_loss: 0.0376 - val_acc: 0.9898\n",
      "Epoch 13/20\n",
      "52500/52500 [==============================] - 113s 2ms/step - loss: 0.0661 - acc: 0.9820 - val_loss: 0.0369 - val_acc: 0.9905\n",
      "Epoch 14/20\n",
      "52500/52500 [==============================] - 115s 2ms/step - loss: 0.0662 - acc: 0.9822 - val_loss: 0.0334 - val_acc: 0.9903\n",
      "Epoch 15/20\n",
      "52500/52500 [==============================] - 115s 2ms/step - loss: 0.0669 - acc: 0.9827 - val_loss: 0.0346 - val_acc: 0.9913\n",
      "Epoch 16/20\n",
      "52500/52500 [==============================] - 98s 2ms/step - loss: 0.0610 - acc: 0.9833 - val_loss: 0.0378 - val_acc: 0.9890\n",
      "Epoch 17/20\n",
      "52500/52500 [==============================] - 94s 2ms/step - loss: 0.0607 - acc: 0.9832 - val_loss: 0.0331 - val_acc: 0.9911\n",
      "Epoch 18/20\n",
      "52500/52500 [==============================] - 94s 2ms/step - loss: 0.0605 - acc: 0.9835 - val_loss: 0.0326 - val_acc: 0.9913\n",
      "Epoch 19/20\n",
      "52500/52500 [==============================] - 95s 2ms/step - loss: 0.0583 - acc: 0.9846 - val_loss: 0.0364 - val_acc: 0.9910\n",
      "Epoch 20/20\n",
      "52500/52500 [==============================] - 95s 2ms/step - loss: 0.0595 - acc: 0.9837 - val_loss: 0.0378 - val_acc: 0.9913\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29e24309ba8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, batch_size=32, epochs=epoch, validation_data=(X_test, Y_test), callbacks=[tbcallback], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.load_weights('./models/weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-ece4fcb8cb00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Test Loss:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Test accuracy:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test Loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_dir = './newmodels/'\n",
    "if not os.path.exists(target_dir):\n",
    "  os.mkdir(target_dir)\n",
    "model.save('./newmodels/model.h5')\n",
    "model.save_weights('./newmodels/weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'numpy.float32' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-1005bdc0e3ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mnumber\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumber\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.float32' object is not iterable"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "#test_image = image.load_img('43.png', target_size=(28,28))\n",
    "ip_img = cv2.imread('54.png')\n",
    "ip_img = cv2.cvtColor(ip_img, cv2.COLOR_BGR2GRAY)\n",
    "ip_img = cv2.resize(ip_img, (28,28))\n",
    "test_image = image.img_to_array(ip_img)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = model.predict(test_image)[0]\n",
    "\n",
    "print(result)\n",
    "number = 0\n",
    "for i in result[0]:\n",
    "    if i == 1:\n",
    "        result = number\n",
    "    number += 1\n",
    "print(\"The Number is = %d\" % result )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Predicting Text from an Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, PythonMagick\n",
    "from PythonMagick import Image\n",
    "from datetime import datetime\n",
    "import PyPDF2\n",
    "import numpy as np\n",
    "import cv2\n",
    "from imutils import contours\n",
    "import imutils\n",
    "import numpy as np\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def x_cord_contour(cnts):\n",
    "    \n",
    "    if cv2.contourArea(cnts) > 5:\n",
    "        M = cv2.moments(cnts)\n",
    "        return (int(M['m10']/M['m00']))\n",
    "    \n",
    "def makeSquare(not_square):\n",
    "    # Adds black pixels as padding\n",
    "    \n",
    "    BLACK = [0, 0, 0]\n",
    "    img_dim = not_square.shape\n",
    "    height = img_dim[0]\n",
    "    width = img_dim[1]\n",
    "    if (height == width):\n",
    "        square = not_square\n",
    "        return square\n",
    "    else:\n",
    "        doublesize = cv2.resize(not_square, (2 * width, 2 * height), interpolation = cv2.INTER_CUBIC)\n",
    "        height = height * 2\n",
    "        width = width * 2\n",
    "        if (height > width):\n",
    "            pad = (height - width)/2\n",
    "            pad = int(pad)\n",
    "            #doublesize = int(doublesize)\n",
    "            doublesize_square = cv2.copyMakeBorder(doublesize, 0, 0, pad,\\\n",
    "                                                  pad, cv2.BORDER_CONSTANT, value = BLACK)\n",
    "        else:\n",
    "            pad = (width - height)/2\n",
    "            pad = int(pad)\n",
    "            doublesize_square = cv2.copyMakeBorder(doublesize, pad, pad, 0, 0,\\\n",
    "                                                  cv2.BORDER_CONSTANT, value = BLACK)\n",
    "    doublesize_square_dim = doublesize_square.shape\n",
    "    return doublesize_square\n",
    "\n",
    "def resize_to_pixel(dimensions, image):\n",
    "    \n",
    "    buffer_pix = 4\n",
    "    dimensions = dimensions - buffer_pix\n",
    "    squared = image\n",
    "    r = float(dimensions)/squared.shape[1]\n",
    "    dim = (dimensions, int(squared.shape[0] * r))\n",
    "    resized = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)\n",
    "    img_dim2 = resized.shape\n",
    "    height_r = img_dim2[0]\n",
    "    widht_r = img_dim2[1]\n",
    "    BLACK = [0, 0, 0]\n",
    "    if (height_r > widht_r):\n",
    "        resized = cv2.copyMakeBorder(resized, 0, 0, 0, 1, cv2.BORDER_CONSTANT, value = BLACK)\n",
    "    if (height_r < widht_r):\n",
    "        resized = cv2.copyMakeBorder(resized, 1, 0, 0, 0, cv2.BORDER_CONSTANT, value = BLACK)\n",
    "    p = 2\n",
    "    ReSizedImg = cv2.copyMakeBorder(resized, p, p, p, p, cv2.BORDER_CONSTANT, value = BLACK)\n",
    "    img_dim = ReSizedImg.shape\n",
    "    height = img_dim[0]\n",
    "    width = img_dim[1]\n",
    "    return ReSizedImg\n",
    "\n",
    "a = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pdf_dir = r\"./Output_PDFs/\"\n",
    "img_dir = r\"./Images/\"\n",
    "bg_colour = \"#ffffff\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "2\n",
      "2\n",
      "8\n",
      "5\n",
      "2\n",
      "2\n",
      "7\n",
      "2\n",
      "8\n",
      "0\n",
      "1\n",
      "5\n",
      "5\n",
      "3\n",
      "2\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "predicted_nums = []\n",
    "for img in [img_file for img_file in os.listdir(img_dir) if img_file.endswith(\".jpg\")]:\n",
    "\n",
    "    input_img = img_dir + img\n",
    "    input_for_detection = cv2.imread(input_img)\n",
    "    #detection(image)\n",
    "    #cv2.imshow('Original', image)\n",
    "    img_scaled = cv2.resize(input_for_detection, None, fx = 0.30, fy = 0.30)\n",
    "    cv2.imshow('Resized',img_scaled)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    # height, width = img_scaled.shape[:2]\n",
    "\n",
    "    # start_row, start_col = height, width\n",
    "\n",
    "    # end_row, end_col = int(height * .95), width\n",
    "\n",
    "    # cropped = img_scaled[start_row:end_row, start_col:end_col]\n",
    "    # cv2.imshow('Cropped',cropped)\n",
    "    # #cv2.imshow('Translation', img_scaled)\n",
    "    # cv2.waitKey()\n",
    "    gray = cv2.cvtColor(img_scaled, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    #cv2.imshow('Gray', gray)\n",
    "    #cv2.waitKey(0)\n",
    "\n",
    "    # Blur image then find edges using Canny\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    #cv2.imshow('Blurred', blurred)\n",
    "    #cv2.waitKey(0)\n",
    "\n",
    "    #ret, regoi = cv2.threshold(blurred, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "    #cv2.imshow('ROI',regoi)\n",
    "    #cv2.waitKey(0)\n",
    "\n",
    "    edged = cv2.Canny(blurred, 65, 150)\n",
    "    cv2.imshow('Edges', edged)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    #lines = cv2.HoughLinesP(edged, 1, np.pi / 180, 300, 5, 5)\n",
    "    #print(lines.shape)\n",
    "\n",
    "    #for x1, y1, x2, y2 in lines[0]:\n",
    "       # cv2.line(image, (x1, y1), (x2, y2), (255, 255, 255), 3)\n",
    "        \n",
    "    # cv2.imshow('lines', image)\n",
    "    # cv2.waitKey(0)\n",
    "\n",
    "    # Find contours\n",
    "    ret, cnts, hierarchy = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Sort out contours left to right by using their x coordinates\n",
    "    #contours = sorted(contours, key = x_cord_contour(contours), reverse = False)\n",
    "\n",
    "\n",
    "    (cnts, boundingBoxes) = contours.sort_contours(cnts, method=\"left-to-right\")\n",
    "    clone = input_for_detection.copy()\n",
    "\n",
    "\n",
    "\n",
    "    # Loop over the contours\n",
    "    # for (i, c) in enumerate(contours)\n",
    "    # for c in contours:\n",
    "    ans =[]\n",
    "    for c in cnts:\n",
    "        # computing bounding box for rectangle\n",
    "        (x, y, w, h) = cv2.boundingRect(c)\n",
    "        \n",
    "        if w >=10 and h >=25:\n",
    "            roi = blurred[y:y +h, x:x + w]\n",
    "            cv2.imshow(\"roi\", roi)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "            ret, roi = cv2.threshold(roi, 170, 255, cv2.THRESH_BINARY_INV)\n",
    "            cv2.imshow(\"roi\", roi)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "            # roi = int(roi)\n",
    "            squared = makeSquare(roi)\n",
    "            final = resize_to_pixel(28, squared)\n",
    "            l = str(a)\n",
    "            cv2.imshow(\"final\", final)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "            predict_img = image.img_to_array(final)\n",
    "            predict_img = np.expand_dims(predict_img, axis = 0)\n",
    "            ans = model.predict(predict_img)\n",
    "            #print(model.predict(predict_img))\n",
    "            number = 0\n",
    "            for i in ans[0]:\n",
    "                if i == 1:\n",
    "                    #print(ans)\n",
    "                    ans = number\n",
    "                    print(ans)\n",
    "                number += 1\n",
    "                \n",
    "            predicted_nums.append(ans)\n",
    "            #print(\"The Number is = %d\" % result )\n",
    "            #cv2.imshow(\"final\", final)\n",
    "            #cv2.imwrite(\"./Detected/img_\"+l+\".jpg\",final)\n",
    "            a= a + 1\n",
    "            #cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Number is = [5, 2, 2, 8, 5, 2, 2, 7, 2, 0, 5, 5, 3, 2, 8]\n"
     ]
    }
   ],
   "source": [
    "print(\"The Number is = \" + str(predicted_nums) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
