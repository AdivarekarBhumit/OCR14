{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.preprocessing import image as im\n",
    "from keras import backend as k\n",
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "model=load_model('finalbestmodel.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get tags from non-filled image\n",
    "def traverseCroppedSections():\n",
    "    labelList = []\n",
    "    for x, y, w, h in coordinates:\n",
    "        croppedSection = cropImage(x, y, w, h, nonfilledimage)\n",
    "        #label = tesseract.image_to_string(croppedSection)\n",
    "        #labelList.append(label)\n",
    "    # push these labels to database along with the coordinates and index\n",
    "    \n",
    "# Cropping the image\n",
    "def cropImage(x, y, w, h, image):\n",
    "    # Crop image here\n",
    "    croppedImage = image[y:y + h,x:x + w]\n",
    "    return croppedImage\n",
    "\n",
    "# function to match template\n",
    "def templateMatching(wholeimage, template):\n",
    "    result = cv2.matchTemplate(wholeimage, template, cv2.TM_CCOEFF)\n",
    "    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\n",
    "    return max_loc[0], max_loc[1]\n",
    "\n",
    "# cropping and setdifferencing function\n",
    "def getNonfilledCroppedSections(coordinates):\n",
    "    for x, y, w, h in coordinates:\n",
    "        # cropping non filled image\n",
    "        nonfilledcroppedsection = cropImage(x, y, w, h, nonfilledimage)\n",
    "        cv2.imshow('nonfilledcroppedsection', nonfilledcroppedsection)\n",
    "        cv2.waitKey(0)\n",
    "        \n",
    "        #dilating \n",
    "        nonfilledcroppedsectiondilated = cropImage(x, y, w, h, nonfilledimagedilated)\n",
    "        \n",
    "        crop_h = nonfilledcroppedsection.shape[0]\n",
    "        crop_w = nonfilledcroppedsection.shape[1]\n",
    "        \n",
    "        crop_x, crop_y = templateMatching(filledimage, nonfilledcroppedsection)\n",
    "        \n",
    "        # cropping the matched template from filled image\n",
    "        filledcroppedsection = cropImage(crop_x, crop_y, crop_w, crop_h, filledimage)\n",
    "        \n",
    "        # subtracting nonfilled image from filled image\n",
    "        setDifference = np.subtract(filledcroppedsection, nonfilledcroppedsection)\n",
    "        cv2.imshow('setDifference', setDifference)\n",
    "        cv2.waitKey(0)\n",
    "        \n",
    "        #setDifference = cv2.medianBlur(setDifference, 3)\n",
    "        \n",
    "        setDifference = cv2.erode(setDifference, np.ones((3, 3), np.uint8), iterations=1)\n",
    "        cv2.imshow('setDifferenceeroded', setDifference)\n",
    "        cv2.waitKey(0)\n",
    "        \n",
    "        converted_to_text = ocr(setDifference)\n",
    "        print(\"converted_to_text\")\n",
    "        \n",
    "        \n",
    "def ocr(image):\n",
    "    # detecting edges in the image\n",
    "    image_edges = cv2.Canny(image, 30, 150)\n",
    "    \n",
    "    # dilating image to detect individual lines\n",
    "    kernel_line = np.ones((10, 80), np.uint8)\n",
    "    dilated_line = cv2.dilate(image_edges, kernel_line, iterations=1)\n",
    "    \n",
    "    # finding contours of the line\n",
    "    im2, ctrs_line, hier = cv2.findContours(dilated_line.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    sorted_ctrs_line = sorted(ctrs_line, key=lambda ctr: cv2.boundingRect(ctr)[1])\n",
    "    \n",
    "    # list of words\n",
    "    word_list = []\n",
    "    \n",
    "    for i, ctr_line in enumerate(sorted_ctrs_line):\n",
    "        # getting coordinates of the line contour\n",
    "        line_x, line_y, line_w, line_h = cv2.boundingRect(ctr_line)\n",
    "        \n",
    "        # if condition for removing unnecessary contours\n",
    "        if line_w * line_h < 10000:\n",
    "            continue\n",
    "        \n",
    "        line = cropImage(line_x, line_y, line_w, line_h, image)\n",
    "        cv2.imshow('line', line)\n",
    "        cv2.waitKey(0)\n",
    "        \n",
    "        # detecting edges in the image\n",
    "        line_edges = cv2.Canny(line, 30, 150)\n",
    "        \n",
    "        # dilating line to detect individual words\n",
    "        kernel_word = np.ones((10, 55), np.uint8)\n",
    "        dilated_word = cv2.dilate(line_edges, kernel_word, iterations=1)\n",
    "        \n",
    "        # finding contours of the word\n",
    "        im2, ctrs_word, hier = cv2.findContours(dilated_word.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        sorted_ctrs_word = sorted(ctrs_word, key=lambda ctr: cv2.boundingRect(ctr)[0])\n",
    "        \n",
    "        for i, ctr_word in enumerate(sorted_ctrs_word):\n",
    "            # getting coordinates of the word contour\n",
    "            word_x, word_y, word_w, word_h = cv2.boundingRect(ctr_word)\n",
    "            \n",
    "            # if condition for removing unnecessary contours\n",
    "            if word_w * word_h < 2500:\n",
    "                continue\n",
    "                \n",
    "            word = cropImage(word_x, word_y, word_w, word_h, line)\n",
    "            cv2.imshow('word', word)\n",
    "            cv2.waitKey(0)\n",
    "            \n",
    "            # detecting edges in the image\n",
    "            word_edges = cv2.Canny(word, 30, 150)\n",
    "            \n",
    "            # dilating word to detect individual characters\n",
    "            kernel_char = np.ones((15, 15), np.uint8)\n",
    "            dilated_char = cv2.dilate(word, kernel_char, iterations=1)\n",
    "            \n",
    "            # finding contours of the characters\n",
    "            im2, ctrs_char, hier = cv2.findContours(dilated_char.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            sorted_ctrs_char = sorted(ctrs_char, key=lambda ctr: cv2.boundingRect(ctr)[0])\n",
    "            \n",
    "            # list of words\n",
    "            character_list = []\n",
    "            \n",
    "            for i, ctr_char in enumerate(sorted_ctrs_char):\n",
    "                # getting coordinates of the character contour\n",
    "                char_x, char_y, char_w, char_h = cv2.boundingRect(ctr_char)\n",
    "                \n",
    "                # if condition for removing unnecessary contours\n",
    "                if char_w * char_h < 180:\n",
    "                    continue\n",
    "                    \n",
    "                charac = cropImage(char_x, char_y, char_w, char_h, word)\n",
    "                cv2.imshow('charac', charac)\n",
    "                cv2.waitKey(0)\n",
    "                cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converted_to_text\n",
      "converted_to_text\n",
      "converted_to_text\n",
      "converted_to_text\n",
      "converted_to_text\n"
     ]
    }
   ],
   "source": [
    "nonfilledimage = cv2.imread('nonfilled_300.jpg',0)\n",
    "nonfilledimage = cv2.threshold(nonfilledimage, 100, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "nonfilledimagedilated = nonfilledimage.copy()\n",
    "nonfilledimagedilated = cv2.dilate(nonfilledimagedilated, np.ones((2, 2), np.uint8), iterations=4)\n",
    "\n",
    "filledimage = cv2.imread('filled_300.jpg',0)\n",
    "filledimage = cv2.threshold(filledimage, 100, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "coordinates = [[196,336,1656,119],[191,981,2137,94],[181,1149,2152,104],[920,2999,620,119],[176,1298,977,128]]\n",
    "\n",
    "getNonfilledCroppedSections(coordinates)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
