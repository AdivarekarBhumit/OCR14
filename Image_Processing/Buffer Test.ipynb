{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Praneet\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.preprocessing import image as im\n",
    "from keras import backend as k\n",
    "import tensorflow as tf\n",
    "import pytesseract as tesseract\n",
    "tf.reset_default_graph()\n",
    "from keras.models import load_model\n",
    "model=load_model('finalbestmodel.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def ocr(image):\\n    \\n    # detecting edges in the image\\n    image_edges = cv2.Canny(image, 30, 150)\\n    \\n    # dilating image to detect individual lines\\n    kernel_line = np.ones((10, 80), np.uint8)\\n    dilated_line = cv2.dilate(image_edges, kernel_line, iterations=1)\\n    \\n    # finding contours of the line\\n    im2, ctrs_line, hier = cv2.findContours(dilated_line.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\\n    sorted_ctrs_line = sorted(ctrs_line, key=lambda ctr: cv2.boundingRect(ctr)[1])\\n    \\n    # list of words\\n    word_list = []\\n    \\n    for i, ctr_line in enumerate(sorted_ctrs_line):\\n        # getting coordinates of the line contour\\n        line_x, line_y, line_w, line_h = cv2.boundingRect(ctr_line)\\n        \\n        # if condition for removing unnecessary contours\\n        if line_w * line_h < 10000:\\n            continue\\n        \\n        line = cropImage(line_x, line_y, line_w, line_h, image)\\n        cv2.imshow(\\'line\\', line)\\n        cv2.waitKey(0)\\n        \\n        # detecting edges in the image\\n        line_edges = cv2.Canny(line, 30, 150)\\n        \\n        # dilating line to detect individual words\\n        kernel_word = np.ones((10, 60), np.uint8)\\n        dilated_word = cv2.dilate(line_edges, kernel_word, iterations=1)\\n        \\n        # finding contours of the word\\n        im2, ctrs_word, hier = cv2.findContours(dilated_word.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\\n        sorted_ctrs_word = sorted(ctrs_word, key=lambda ctr: cv2.boundingRect(ctr)[0])\\n        \\n        for i, ctr_word in enumerate(sorted_ctrs_word):\\n            # getting coordinates of the word contour\\n            word_x, word_y, word_w, word_h = cv2.boundingRect(ctr_word)\\n            \\n            # if condition for removing unnecessary contours\\n            if word_w * word_h < 2500:\\n                continue\\n            \\n            #print(\"Word \" + str(word_x), str(word_y), str(word_w), str(word_h))\\n            \\n            word = cropImage(word_x, word_y, word_w, word_h, line)\\n            cv2.imshow(\\'word\\', word)\\n            cv2.waitKey(0)\\n            \\n            word = cv2.erode(word, np.ones((1, 1), np.uint8), iterations=1)\\n            \\n            # detecting edges in the image\\n            word_edges = cv2.Canny(word, 30, 150)\\n            \\n            # dilating word to detect individual characters\\n            kernel_char = np.ones((15, 3), np.uint8)\\n            dilated_char = cv2.dilate(word_edges, kernel_char, iterations=1)\\n            cv2.imshow(\\'dilated_char\\', dilated_char)\\n            cv2.waitKey(0)\\n            \\n            # finding contours of the characters\\n            im2, ctrs_char, hier = cv2.findContours(dilated_char.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\\n            sorted_ctrs_char = sorted(ctrs_char, key=lambda ctr: cv2.boundingRect(ctr)[0])\\n            \\n            # list of words\\n            character_list = []\\n            \\n            for i, ctr_char in enumerate(sorted_ctrs_char):\\n                # getting coordinates of the character contour\\n                char_x, char_y, char_w, char_h = cv2.boundingRect(ctr_char)\\n                \\n                # if condition for removing unnecessary contours\\n                if char_w * char_h < 180:\\n                    continue\\n                    \\n                #print(\"Character \" + str(char_x), str(char_y), str(char_w), str(char_h))\\n                \\n                charac = cropImage(char_x, char_y, char_w, char_h, word)\\n                #cv2.imshow(\\'charac\\', charac)\\n                #cv2.waitKey(0)\\n                #cv2.destroyAllWindows()\\n                \\n                character = prediction(charac)\\n                character_list.append(character)\\n            word_list.append(\"\".join(character_list))\\n    recognized_text = \" \".join(word_list)\\n    return recognized_text'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get tags from non-filled image\n",
    "def traverseCroppedSections():\n",
    "    labelList = []\n",
    "    for x, y, w, h in coordinates:\n",
    "        croppedSection = cropImage(x, y, w, h, nonfilledtesseract)\n",
    "        label = tesseract.image_to_string(croppedSection)\n",
    "        labelList.append(label)\n",
    "    print(labelList)\n",
    "    # push these labels to database along with the coordinates and index\n",
    "    \n",
    "# Cropping the image\n",
    "def cropImage(x, y, w, h, image):\n",
    "    # Crop image here\n",
    "    croppedImage = image[y:y + h,x:x + w]\n",
    "    return croppedImage\n",
    "\n",
    "# function to match template\n",
    "def templateMatching(wholeimage, template):\n",
    "    result = cv2.matchTemplate(wholeimage, template, cv2.TM_CCOEFF)\n",
    "    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\n",
    "    return max_loc[0], max_loc[1]\n",
    "\n",
    "def makeSquare(not_square):\n",
    "    # Adds black pixels as padding\n",
    "    \n",
    "    BLACK = [0, 0, 0]\n",
    "    img_dim = not_square.shape\n",
    "    height = img_dim[0]\n",
    "    width = img_dim[1]\n",
    "    if (height == width):\n",
    "        square = not_square\n",
    "        return square\n",
    "    else:\n",
    "        doublesize = cv2.resize(not_square, (2 * width, 2 * height), interpolation = cv2.INTER_CUBIC)\n",
    "        height = height * 2\n",
    "        width = width * 2\n",
    "        if (height > width):\n",
    "            pad = (height - width)/2\n",
    "            pad = int(pad)\n",
    "            #doublesize = int(doublesize)\n",
    "            doublesize_square = cv2.copyMakeBorder(doublesize, 0, 0, pad,\\\n",
    "                                                  pad, cv2.BORDER_CONSTANT, value = BLACK)\n",
    "        else:\n",
    "            pad = (width - height)/2\n",
    "            pad = int(pad)\n",
    "            doublesize_square = cv2.copyMakeBorder(doublesize, pad, pad, 0, 0,\\\n",
    "                                                  cv2.BORDER_CONSTANT, value = BLACK)\n",
    "    doublesize_square_dim = doublesize_square.shape\n",
    "    return doublesize_square\n",
    "\n",
    "def resize_to_pixel(dimensions, image):\n",
    "    \n",
    "    buffer_pix = 4\n",
    "    dimensions = dimensions - buffer_pix\n",
    "    squared = image\n",
    "    r = float(dimensions)/squared.shape[1]\n",
    "    dim = (dimensions, int(squared.shape[0] * r))\n",
    "    resized = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)\n",
    "    img_dim2 = resized.shape\n",
    "    height_r = img_dim2[0]\n",
    "    widht_r = img_dim2[1]\n",
    "    BLACK = [0, 0, 0]\n",
    "    if (height_r > widht_r):\n",
    "        resized = cv2.copyMakeBorder(resized, 0, 0, 0, 1, cv2.BORDER_CONSTANT, value = BLACK)\n",
    "    if (height_r < widht_r):\n",
    "        resized = cv2.copyMakeBorder(resized, 1, 0, 0, 0, cv2.BORDER_CONSTANT, value = BLACK)\n",
    "    p = 2\n",
    "    ReSizedImg = cv2.copyMakeBorder(resized, p, p, p, p, cv2.BORDER_CONSTANT, value = BLACK)\n",
    "    img_dim = ReSizedImg.shape\n",
    "    height = img_dim[0]\n",
    "    width = img_dim[1]\n",
    "    return ReSizedImg\n",
    "\n",
    "\n",
    "def prediction(char_image):\n",
    "    squared = makeSquare(char_image)\n",
    "    size28 = resize_to_pixel(28, squared)\n",
    "    cv2.imshow('char resized', size28)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()     \n",
    "    predict_img = im.img_to_array(size28)\n",
    "    predict_img = np.expand_dims(predict_img, axis = 0)\n",
    "    predictedarray = model.predict(predict_img)\n",
    "    index = calculateClass(predictedarray[0])\n",
    "    \n",
    "    predicted_class = label_dictionary[index]\n",
    "    return predicted_class\n",
    "\n",
    "def calculateClass(predictedarray):\n",
    "    predictedclass = 0\n",
    "    predictedclassindex = 0\n",
    "    index = 0\n",
    "    for classprediction in predictedarray:\n",
    "        if classprediction > predictedclass:\n",
    "            predictedclass = classprediction\n",
    "            predictedclassindex = index\n",
    "        index = index + 1\n",
    "    return predictedclassindex\n",
    "\n",
    "def histogramSegmentation(img):\n",
    "    #int(img.shape[1] * (1/5))\n",
    "    print(img.shape[1])\n",
    "    THRESHOLD = int(img.shape[1] * (1/7.5))\n",
    "    print(THRESHOLD)\n",
    "    histogramResults = []\n",
    "    \n",
    "    col_histo_width = img.shape[1]\n",
    "    col_histo_height = img.shape[0]\n",
    "    col_histogram = np.zeros((col_histo_height, col_histo_width), np.uint8)\n",
    "\n",
    "    # Initializing horizontal histogram\n",
    "    row_histo_height = img.shape[0]\n",
    "    row_histo_width = img.shape[1]\n",
    "    row_histogram = np.zeros((row_histo_height, row_histo_width), np.uint8)\n",
    "\n",
    "    colsums = []\n",
    "    startflag = False\n",
    "    endflag = True\n",
    "    for col in range(col_histo_width):\n",
    "        running_sum = sum(img[:, col]) // 255\n",
    "        if startflag == False and running_sum >= THRESHOLD:\n",
    "            startindex = col\n",
    "            if (startindex < 0):\n",
    "                startindex = 0\n",
    "            startflag = True\n",
    "            endflag = False\n",
    "        if endflag == False and running_sum <= THRESHOLD:\n",
    "            endindex = col\n",
    "            if endindex > col_histo_width:\n",
    "                endindex = col_histo_width\n",
    "            endflag = True\n",
    "            startflag = False\n",
    "            if startindex != endindex:\n",
    "                histogramResults.append((startindex, endindex))\n",
    "                print((startindex, endindex))\n",
    "        colsums.append(running_sum)\n",
    "    return histogramResults\n",
    "\n",
    "\n",
    "# cropping and setdifferencing function\n",
    "def getNonfilledCroppedSections(coordinates):\n",
    "    i = 0\n",
    "    for x, y, w, h in coordinates:\n",
    "        \n",
    "        tag = tags[i]\n",
    "        i = i + 1\n",
    "        \n",
    "        # cropping non filled image\n",
    "        nonfilledcroppedsection = cropImage(x, y, w, h, nonfilledimage)\n",
    "        cv2.imshow('nonfilledcroppedsection', nonfilledcroppedsection)\n",
    "        cv2.waitKey(0)\n",
    "        \n",
    "        #dilating \n",
    "        nonfilledcroppedsectiondilated = cropImage(x, y, w, h, nonfilledimagedilated)\n",
    "        \n",
    "        crop_h = nonfilledcroppedsection.shape[0]\n",
    "        crop_w = nonfilledcroppedsection.shape[1]\n",
    "        \n",
    "        buffer_x = x - 75\n",
    "        buffer_y = y - 75\n",
    "        buffer_w = w + 2*75\n",
    "        buffer_h = h + 2*75\n",
    "        \n",
    "        if ( buffer_x < 0 ):\n",
    "            buffer_x = 0\n",
    "        if ( buffer_y < 0 ):\n",
    "            buffer_y = 0\n",
    "        if ( buffer_x + buffer_w > filledimage.shape[0] ):\n",
    "            buffer_w = filledimage.shape[0]\n",
    "        if ( buffer_y + buffer_h > filledimage.shape[1] ):\n",
    "            buffer_h = filledimage.shape[1]\n",
    "            \n",
    "        filledcroppedsectionbuffer = cropImage(buffer_x, buffer_y, buffer_w, buffer_h, filledimagedilated)\n",
    "        cv2.imshow('filledcroppedsectionbuffer', filledcroppedsectionbuffer)\n",
    "        cv2.waitKey(0)\n",
    "        \n",
    "        # To use for set difference\n",
    "        filledcroppedsectionbuffernondilated = cropImage(buffer_x, buffer_y, buffer_w, buffer_h, filledimage)\n",
    "        \n",
    "        #crop_x, crop_y = templateMatching(filledcroppedsectionbuffer, nonfilledcroppedsection)\n",
    "        crop_x, crop_y = templateMatching(filledcroppedsectionbuffernondilated, nonfilledcroppedsection)\n",
    "        \n",
    "        # cropping the matched template from filled image\n",
    "        filledcroppedsection = cropImage(buffer_x + crop_x, buffer_y + crop_y, crop_w, crop_h, filledimage)\n",
    "        cv2.imshow('filledcroppedsection', filledcroppedsection)\n",
    "        cv2.waitKey(0)\n",
    "        \n",
    "        # subtracting nonfilled image from filled image\n",
    "        setDifference = np.subtract(filledcroppedsection, nonfilledcroppedsection)\n",
    "        cv2.imshow('setDifference', setDifference)\n",
    "        cv2.waitKey(0)\n",
    "        \n",
    "        setDifference = cv2.medianBlur(setDifference, 3)\n",
    "        #setDifference = cv2.erode(setDifference, np.ones((3, 3), np.uint8), iterations=1)\n",
    "        cv2.imshow('setDifferenceeroded', setDifference)\n",
    "        cv2.waitKey(0)\n",
    "        \n",
    "        converted_to_text = ocr(setDifference)\n",
    "        print(tag + ' : ' + converted_to_text)\n",
    "        \n",
    "        \n",
    "\"\"\"def ocr(image):\n",
    "    \n",
    "    # detecting edges in the image\n",
    "    image_edges = cv2.Canny(image, 30, 150)\n",
    "    \n",
    "    # dilating image to detect individual lines\n",
    "    kernel_line = np.ones((10, 80), np.uint8)\n",
    "    dilated_line = cv2.dilate(image_edges, kernel_line, iterations=1)\n",
    "    \n",
    "    # finding contours of the line\n",
    "    im2, ctrs_line, hier = cv2.findContours(dilated_line.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    sorted_ctrs_line = sorted(ctrs_line, key=lambda ctr: cv2.boundingRect(ctr)[1])\n",
    "    \n",
    "    # list of words\n",
    "    word_list = []\n",
    "    \n",
    "    for i, ctr_line in enumerate(sorted_ctrs_line):\n",
    "        # getting coordinates of the line contour\n",
    "        line_x, line_y, line_w, line_h = cv2.boundingRect(ctr_line)\n",
    "        \n",
    "        # if condition for removing unnecessary contours\n",
    "        if line_w * line_h < 10000:\n",
    "            continue\n",
    "        \n",
    "        line = cropImage(line_x, line_y, line_w, line_h, image)\n",
    "        cv2.imshow('line', line)\n",
    "        cv2.waitKey(0)\n",
    "        \n",
    "        # detecting edges in the image\n",
    "        line_edges = cv2.Canny(line, 30, 150)\n",
    "        \n",
    "        # dilating line to detect individual words\n",
    "        kernel_word = np.ones((10, 60), np.uint8)\n",
    "        dilated_word = cv2.dilate(line_edges, kernel_word, iterations=1)\n",
    "        \n",
    "        # finding contours of the word\n",
    "        im2, ctrs_word, hier = cv2.findContours(dilated_word.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        sorted_ctrs_word = sorted(ctrs_word, key=lambda ctr: cv2.boundingRect(ctr)[0])\n",
    "        \n",
    "        for i, ctr_word in enumerate(sorted_ctrs_word):\n",
    "            # getting coordinates of the word contour\n",
    "            word_x, word_y, word_w, word_h = cv2.boundingRect(ctr_word)\n",
    "            \n",
    "            # if condition for removing unnecessary contours\n",
    "            if word_w * word_h < 2500:\n",
    "                continue\n",
    "            \n",
    "            #print(\"Word \" + str(word_x), str(word_y), str(word_w), str(word_h))\n",
    "            \n",
    "            word = cropImage(word_x, word_y, word_w, word_h, line)\n",
    "            cv2.imshow('word', word)\n",
    "            cv2.waitKey(0)\n",
    "            \n",
    "            word = cv2.erode(word, np.ones((1, 1), np.uint8), iterations=1)\n",
    "            \n",
    "            # detecting edges in the image\n",
    "            word_edges = cv2.Canny(word, 30, 150)\n",
    "            \n",
    "            # dilating word to detect individual characters\n",
    "            kernel_char = np.ones((15, 3), np.uint8)\n",
    "            dilated_char = cv2.dilate(word_edges, kernel_char, iterations=1)\n",
    "            cv2.imshow('dilated_char', dilated_char)\n",
    "            cv2.waitKey(0)\n",
    "            \n",
    "            # finding contours of the characters\n",
    "            im2, ctrs_char, hier = cv2.findContours(dilated_char.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            sorted_ctrs_char = sorted(ctrs_char, key=lambda ctr: cv2.boundingRect(ctr)[0])\n",
    "            \n",
    "            # list of words\n",
    "            character_list = []\n",
    "            \n",
    "            for i, ctr_char in enumerate(sorted_ctrs_char):\n",
    "                # getting coordinates of the character contour\n",
    "                char_x, char_y, char_w, char_h = cv2.boundingRect(ctr_char)\n",
    "                \n",
    "                # if condition for removing unnecessary contours\n",
    "                if char_w * char_h < 180:\n",
    "                    continue\n",
    "                    \n",
    "                #print(\"Character \" + str(char_x), str(char_y), str(char_w), str(char_h))\n",
    "                \n",
    "                charac = cropImage(char_x, char_y, char_w, char_h, word)\n",
    "                #cv2.imshow('charac', charac)\n",
    "                #cv2.waitKey(0)\n",
    "                #cv2.destroyAllWindows()\n",
    "                \n",
    "                character = prediction(charac)\n",
    "                character_list.append(character)\n",
    "            word_list.append(\"\".join(character_list))\n",
    "    recognized_text = \" \".join(word_list)\n",
    "    return recognized_text\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Pran nonfilled\n",
    "nonfilledimage = cv2.imread('nonfilledaadhar.jpg',0)\n",
    "\n",
    "# IELTS nonfilled\n",
    "#nonfilledimage = cv2.imread('nonfilled_0.jpg',0)\n",
    "\n",
    "nonfilledimage = cv2.threshold(nonfilledimage, 100, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "nonfilledtesseract = nonfilledimage\n",
    "\n",
    "nonfilledimagedilated = nonfilledimage.copy()\n",
    "nonfilledimagedilated = cv2.dilate(nonfilledimagedilated, np.ones((2, 2), np.uint8), iterations=4)\n",
    "nonfilledimage = nonfilledimagedilated\n",
    "\n",
    "# Pran filled\n",
    "filledimage = cv2.imread('filledaadhar.jpg',0)\n",
    "\n",
    "# IELTS filled\n",
    "#filledimage = cv2.imread('filled_0.jpg',0)\n",
    "\n",
    "filledimage = cv2.threshold(filledimage, 100, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "filledimagedilated = cv2.dilate(filledimage, np.ones((2, 2), np.uint8), iterations=4)\n",
    "\n",
    "# PRAN\n",
    "#coordinates = [[196,336,1656,119],[191,981,2137,94],[920,2999,620,119],[176,1298,977,128]]\n",
    "# aadhar\n",
    "coordinates = [[243,585,951,89],[237,679,2003,79],[242,962,927,84],[1750,1309,515,89]]\n",
    "\n",
    "label_dictionary = {0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '9', 10: 'a',\n",
    "                    11: 'b', 12: 'd', 13: 'e', 14: 'f', 15: 'g', 16: 'h', 17: 'i', 18: 'j', 19: 'l', 20: 'm',\n",
    "                    21: 'n', 22: 'q', 23: 'r', 24: 't', 25: 'y', 26: 'A', 27: 'B', 28: 'C', 29: 'D', 30: 'E',\n",
    "                    31: 'F', 32: 'G', 33: 'H', 34: 'I', 35: 'J', 36: 'K', 37: 'L', 38: 'M', 39: 'N', 40: 'O',\n",
    "                    41: 'P', 42: 'Q', 43: 'R', 44: 'S', 45: 'T', 46: 'U', 47: 'V', 48: 'W', 49: 'X', 50: 'Y',\n",
    "                    51: 'Z'}\n",
    "\n",
    "# pran tags\n",
    "#tags = ['Acknowledge No','First Name','Phone No','DOB']\n",
    "# aadhar tags\n",
    "tags = ['Pre Enrolment ID','Full Name:','House No BIdg Apt','PINCODE']\n",
    "               \n",
    "#tags_index = 0\n",
    "\n",
    "test = cv2.imread('vrkIj.png',0)\n",
    "test = cv2.threshold(nonfilledimage, 100, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "print(ocr(test))\n",
    "\n",
    "#getNonfilledCroppedSections(coordinates)\n",
    "#traverseCroppedSections()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from keras.preprocessing import image as im\n",
    "#import image\n",
    "image = cv2.imread('vrkIj.png')\n",
    "c = image.copy()\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "#pprint(gray, indent=2)\n",
    "\n",
    "# binary\n",
    "ret, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "#cv2.imshow('second', thresh)\n",
    "# cv2.waitKey(0)\n",
    "\n",
    "# dilation\n",
    "kernel = np.ones((10, 80), np.uint8)\n",
    "# original values 5,100\n",
    "img_dilation = cv2.dilate(thresh, kernel, iterations=1)\n",
    "#cv2.imshow('dilated', img_dilation)\n",
    "# cv2.waitKey(0)\n",
    "\n",
    "# find contours\n",
    "im2, ctrs, hier = cv2.findContours(\n",
    "    img_dilation.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# sort contours\n",
    "sorted_ctrs = sorted(ctrs, key=lambda ctr: cv2.boundingRect(ctr)[1])\n",
    "i = 1\n",
    "cropped_images = []\n",
    "for i, ctr in enumerate(sorted_ctrs):\n",
    "    # Get bounding box\n",
    "    x, y, w, h = cv2.boundingRect(ctr)\n",
    "    dimensions = [x, y, w, h]\n",
    "    # Getting ROI\n",
    "    roi = c[y:y + h, x:x + w]\n",
    "    cropped_images.append(dimensions)\n",
    "    #cv2.imwrite('test' + str(i) + '.jpg', roi)\n",
    "    i += 1\n",
    "    # show ROI\n",
    "\n",
    "    #cv2.imshow('segment no:'+str(i),roi)\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (90, 0, 255), 2)\n",
    "    # cv2.waitKey(0)\n",
    "\n",
    "j = 1\n",
    "for x, y, w, h in cropped_images:\n",
    "    img = c[y:y + h, x:x + w]\n",
    "    d = img.copy()\n",
    "    #cv2.imwrite('test' + str(j) + '.jpg', img)\n",
    "    j += 1\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    #cv2.imshow('orig', gray)\n",
    "    # cv2.waitKey(0)\n",
    "    ret, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "    #cv2.imshow('orig', thresh)\n",
    "    # cv2.waitKey(0)\n",
    "    kernel = np.ones((10, 15), np.uint8)\n",
    "    img_dilation = cv2.dilate(thresh, kernel, iterations=1)\n",
    "    #cv2.imshow('orig', img_dilation)\n",
    "    #cv2.waitKey(0)\n",
    "    im2, ctrs, hier = cv2.findContours(\n",
    "        img_dilation.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    sorted_ctrs = sorted(ctrs, key=lambda ctr: cv2.boundingRect(ctr)[0])\n",
    "    i = 1\n",
    "    #cv2.destroyAllWindows()\n",
    "    images = []\n",
    "    for i, ctr in enumerate(sorted_ctrs):\n",
    "        # Get bounding box\n",
    "        x, y, w, h = cv2.boundingRect(ctr)\n",
    "        # Getting ROI\n",
    "        roi = d[y:y + h, x:x + w]\n",
    "\n",
    "        # cv2.imshow('test', roi)\n",
    "        # cv2.waitKey(0)\n",
    "        # cv2.destroyAllWindows()\n",
    "        cv2.imwrite('test' + str(i) + '.jpg', roi)\n",
    "        new_image = cv2.imread('test' + str(i) + '.jpg')\n",
    "        gray = cv2.cvtColor(new_image, cv2.COLOR_BGR2GRAY)\n",
    "        ret, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "        kernel = np.ones((10, 1), np.uint8)\n",
    "        img_dilation = cv2.dilate(thresh, kernel, iterations=1)\n",
    "        #cv2.imshow('dilation', img_dilation)\n",
    "        #cv2.waitKey(0)\n",
    "        #cv2.destroyAllWindows()\n",
    "        im2, ctrs, hier = cv2.findContours(\n",
    "            img_dilation.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        e = thresh.copy()\n",
    "        sorted_ctrs = sorted(ctrs, key=lambda ctr: cv2.boundingRect(ctr)[0])\n",
    "        character_list = []\n",
    "        for i, ctr in enumerate(sorted_ctrs):\n",
    "            # Get bounding box\n",
    "            x, y, w, h = cv2.boundingRect(ctr)\n",
    "            #dimensions = [x, y, w, h]\n",
    "            # Getting ROI\n",
    "            roi = e[y:y + h, x:x + w]\n",
    "            squared = makeSquare(roi)\n",
    "            final = resize_to_pixel(28, squared)\n",
    "            \n",
    "            predict_img = im.img_to_array(final)\n",
    "            predict_img = np.expand_dims(predict_img, axis = 0)\n",
    "            result = model.predict(predict_img)\n",
    "            \n",
    "            number = 0\n",
    "            \n",
    "            \n",
    "            for i in result[0]:\n",
    "                if i > 0:\n",
    "                    character_list.append(number)\n",
    "                number += 1\n",
    "            \n",
    "            #cv2.imshow('test', roi)\n",
    "            #cv2.waitKey(0)\n",
    "            #cv2.destroyAllWindows()\n",
    "            # cropped_images.append(dimensions)\n",
    "            #cv2.imwrite('test' + str(i) + '.jpg', roi)\n",
    "            #i += 1\n",
    "            # show ROI\n",
    "\n",
    "            #cv2.imshow('segment no:'+str(i),roi)\n",
    "            #cv2.rectangle(image, (x, y), (x + w, y + h), (90, 0, 255), 2)\n",
    "        words = []\n",
    "        for character in character_list:\n",
    "            words.append(label_dictionary[character])\n",
    "        print(\"\".join(words))\n",
    "        \"\"\"for character in character_list:\n",
    "            print(\"\".join())\n",
    "            print(\"%s\" % label_dictionary[character] )\"\"\"\n",
    "        # for x_new, y_new, w_new, h_new in roi\n",
    "        # cv2.imwrite('test' + str(i) + '.jpg', roi)\n",
    "        #images.append([x, y, w, h])\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ocr(image):\n",
    "    \n",
    "    # detecting edges in the image\n",
    "    image_edges = cv2.Canny(image, 30, 150)\n",
    "    \n",
    "    # dilating image to detect individual lines\n",
    "    kernel_line = np.ones((10, 80), np.uint8)\n",
    "    dilated_line = cv2.dilate(image_edges, kernel_line, iterations=1)\n",
    "    cv2.imshow('dilated_line', dilated_line)\n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "    # finding contours of the line\n",
    "    im2, ctrs_line, hier = cv2.findContours(dilated_line.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    sorted_ctrs_line = sorted(ctrs_line, key=lambda ctr: cv2.boundingRect(ctr)[1])\n",
    "    \n",
    "    # list of words\n",
    "    word_list = []\n",
    "    \n",
    "    for i, ctr_line in enumerate(sorted_ctrs_line):\n",
    "        # getting coordinates of the line contour\n",
    "        line_x, line_y, line_w, line_h = cv2.boundingRect(ctr_line)\n",
    "        \n",
    "        # if condition for removing unnecessary contours\n",
    "        #         if line_w * line_h < 10000:\n",
    "        #             continue\n",
    "        \n",
    "        line = cropImage(line_x, line_y, line_w, line_h, image)\n",
    "        cv2.imshow('line', line)\n",
    "        cv2.waitKey(0)\n",
    "        \n",
    "        # detecting edges in the image\n",
    "        line_edges = cv2.Canny(line, 30, 150)\n",
    "        \n",
    "        # dilating line to detect individual words\n",
    "        kernel_word = np.ones((10, 60), np.uint8)\n",
    "        dilated_word = cv2.dilate(line_edges, kernel_word, iterations=1)\n",
    "        \n",
    "        # finding contours of the word\n",
    "        im2, ctrs_word, hier = cv2.findContours(dilated_word.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        sorted_ctrs_word = sorted(ctrs_word, key=lambda ctr: cv2.boundingRect(ctr)[0])\n",
    "        \n",
    "        for i, ctr_word in enumerate(sorted_ctrs_word):\n",
    "            # getting coordinates of the word contour\n",
    "            word_x, word_y, word_w, word_h = cv2.boundingRect(ctr_word)\n",
    "            \n",
    "            # if condition for removing unnecessary contours\n",
    "            #             if word_w * word_h < 2500:\n",
    "            #                 continue\n",
    "            \n",
    "            #print(\"Word \" + str(word_x), str(word_y), str(word_w), str(word_h))\n",
    "            \n",
    "            word = cropImage(word_x, word_y, word_w, word_h, line)\n",
    "            cv2.imshow('word', word)\n",
    "            cv2.waitKey(0)\n",
    "            \n",
    "            word = cv2.erode(word, np.ones((1, 1), np.uint8), iterations=1)\n",
    "            \n",
    "            # detecting edges in the image\n",
    "            word_edges = cv2.Canny(word, 30, 150)\n",
    "            \n",
    "            # dilating word to detect individual characters\n",
    "            kernel_char = np.ones((15, 3), np.uint8)\n",
    "            dilated_char = cv2.dilate(word_edges, kernel_char, iterations=1)\n",
    "            cv2.imshow('dilated_char', dilated_char)\n",
    "            cv2.waitKey(0)\n",
    "            \n",
    "            # finding contours of the characters\n",
    "            im2, ctrs_char, hier = cv2.findContours(dilated_char.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            sorted_ctrs_char = sorted(ctrs_char, key=lambda ctr: cv2.boundingRect(ctr)[0])\n",
    "            \n",
    "            # list of words\n",
    "            character_list = []\n",
    "            \n",
    "            for i, ctr_char in enumerate(sorted_ctrs_char):\n",
    "                # getting coordinates of the character contour\n",
    "                char_x, char_y, char_w, char_h = cv2.boundingRect(ctr_char)\n",
    "                \n",
    "                # if condition for removing unnecessary contours\n",
    "                #                 if char_w * char_h < 180:\n",
    "                #                     continue\n",
    "                    \n",
    "                #print(\"Character \" + str(char_x), str(char_y), str(char_w), str(char_h))\n",
    "                \n",
    "                charac = cropImage(char_x, char_y, char_w, char_h, word)\n",
    "                #cv2.imshow('charac', charac)\n",
    "                #cv2.waitKey(0)\n",
    "                #cv2.destroyAllWindows()\n",
    "                \n",
    "                character = prediction(charac)\n",
    "                character_list.append(character)\n",
    "            word_list.append(\"\".join(character_list))\n",
    "    recognized_text = \" \".join(word_list)\n",
    "    return recognized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MELL0 W0RLD aUlCK BR0WN F0X JUMPS heLl0 W0Rld 9UiCK J br0Wn f0X jUmPS\n"
     ]
    }
   ],
   "source": [
    "test = cv2.imread('abc.jpg',0)\n",
    "test = cv2.threshold(test, 100, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "cv2.imshow('char resized', test)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "#print(ocr(test))\n",
    "ocr(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Praneet\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import load_model\n",
    "tf.reset_default_graph()\n",
    "model=load_model('finalbestmodel.hdf5')\n",
    "from keras.preprocessing import image as im\n",
    "\n",
    "label_dictionary = {0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '9', 10: 'a',\n",
    "                    11: 'b', 12: 'd', 13: 'e', 14: 'f', 15: 'g', 16: 'h', 17: 'i', 18: 'j', 19: 'l', 20: 'm',\n",
    "                    21: 'n', 22: 'q', 23: 'r', 24: 't', 25: 'y', 26: 'A', 27: 'B', 28: 'C', 29: 'D', 30: 'E',\n",
    "                    31: 'F', 32: 'G', 33: 'H', 34: 'I', 35: 'J', 36: 'K', 37: 'L', 38: 'M', 39: 'N', 40: 'O',\n",
    "                    41: 'P', 42: 'Q', 43: 'R', 44: 'S', 45: 'T', 46: 'U', 47: 'V', 48: 'W', 49: 'X', 50: 'Y',\n",
    "                    51: 'Z'}\n",
    "\n",
    "def makeSquare(not_square):\n",
    "    # Adds black pixels as padding\n",
    "    \n",
    "    BLACK = [0, 0, 0]\n",
    "    img_dim = not_square.shape\n",
    "    height = img_dim[0]\n",
    "    width = img_dim[1]\n",
    "    if (height == width):\n",
    "        square = not_square\n",
    "        return square\n",
    "    else:\n",
    "        doublesize = cv2.resize(not_square, (2 * width, 2 * height), interpolation = cv2.INTER_CUBIC)\n",
    "        height = height * 2\n",
    "        width = width * 2\n",
    "        if (height > width):\n",
    "            pad = (height - width)/2\n",
    "            pad = int(pad)\n",
    "            #doublesize = int(doublesize)\n",
    "            doublesize_square = cv2.copyMakeBorder(doublesize, 0, 0, pad,\\\n",
    "                                                  pad, cv2.BORDER_CONSTANT, value = BLACK)\n",
    "        else:\n",
    "            pad = (width - height)/2\n",
    "            pad = int(pad)\n",
    "            doublesize_square = cv2.copyMakeBorder(doublesize, pad, pad, 0, 0,\\\n",
    "                                                  cv2.BORDER_CONSTANT, value = BLACK)\n",
    "    doublesize_square_dim = doublesize_square.shape\n",
    "    return doublesize_square\n",
    "\n",
    "def resize_to_pixel(dimensions, image):\n",
    "    \n",
    "    buffer_pix = 4\n",
    "    dimensions = dimensions - buffer_pix\n",
    "    squared = image\n",
    "    r = float(dimensions)/squared.shape[1]\n",
    "    dim = (dimensions, int(squared.shape[0] * r))\n",
    "    resized = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)\n",
    "    img_dim2 = resized.shape\n",
    "    height_r = img_dim2[0]\n",
    "    widht_r = img_dim2[1]\n",
    "    BLACK = [0, 0, 0]\n",
    "    if (height_r > widht_r):\n",
    "        resized = cv2.copyMakeBorder(resized, 0, 0, 0, 1, cv2.BORDER_CONSTANT, value = BLACK)\n",
    "    if (height_r < widht_r):\n",
    "        resized = cv2.copyMakeBorder(resized, 1, 0, 0, 0, cv2.BORDER_CONSTANT, value = BLACK)\n",
    "    p = 2\n",
    "    ReSizedImg = cv2.copyMakeBorder(resized, p, p, p, p, cv2.BORDER_CONSTANT, value = BLACK)\n",
    "    img_dim = ReSizedImg.shape\n",
    "    height = img_dim[0]\n",
    "    width = img_dim[1]\n",
    "    return ReSizedImg\n",
    "\n",
    "def calculateClass(predictedarray):\n",
    "    predictedclass = 0\n",
    "    predictedclassindex = 0\n",
    "    index = 0\n",
    "    for classprediction in predictedarray:\n",
    "        if classprediction > predictedclass:\n",
    "            predictedclass = classprediction\n",
    "            predictedclassindex = index\n",
    "        index = index + 1\n",
    "    return predictedclassindex\n",
    "\n",
    "def prediction(char_image):\n",
    "    squared = makeSquare(char_image)\n",
    "    size28 = resize_to_pixel(28, squared)\n",
    "    cv2.imshow('char resized', size28)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()     \n",
    "    predict_img = im.img_to_array(size28)\n",
    "    predict_img = np.expand_dims(predict_img, axis = 0)\n",
    "    predictedarray = model.predict(predict_img)\n",
    "    index = calculateClass(predictedarray[0])\n",
    "    \n",
    "    predicted_class = label_dictionary[index]\n",
    "    return predicted_class\n",
    "\n",
    "def cropImage(x, y, w, h, image):\n",
    "    # Crop image here\n",
    "    croppedImage = image[y:y + h,x:x + w]\n",
    "    return croppedImage\n",
    "\n",
    "def ocr(image):\n",
    "    kernel_line = np.ones((10, 80), np.uint8)\n",
    "    dilated_line = cv2.dilate(image, kernel_line, iterations=1)\n",
    "    cv2.imshow('dilated_line', dilated_line)\n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "    im2, ctrs_line, hier = cv2.findContours(dilated_line.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    sorted_ctrs_line = sorted(ctrs_line, key=lambda ctr: cv2.boundingRect(ctr)[1])\n",
    "    \n",
    "    word_list = []\n",
    "    \n",
    "    for i, ctr_line in enumerate(sorted_ctrs_line):\n",
    "        line_x, line_y, line_w, line_h = cv2.boundingRect(ctr_line)\n",
    "        line = cropImage(line_x, line_y, line_w, line_h, image)\n",
    "        \n",
    "        kernel_word = np.ones((10, 40), np.uint8)\n",
    "        dilated_word = cv2.dilate(line, kernel_word, iterations=1)\n",
    "        cv2.imshow('dilated_word', dilated_word)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "        im2, ctrs_word, hier = cv2.findContours(dilated_word.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        sorted_ctrs_word = sorted(ctrs_word, key=lambda ctr: cv2.boundingRect(ctr)[0])\n",
    "        \n",
    "        for i, ctr_word in enumerate(sorted_ctrs_word):\n",
    "            word_x, word_y, word_w, word_h = cv2.boundingRect(ctr_word)\n",
    "            \n",
    "            word = cropImage(word_x, word_y, word_w, word_h, line)\n",
    "            cv2.imshow('word', word)\n",
    "            cv2.waitKey(0)\n",
    "            \n",
    "            word = cv2.erode(word, np.ones((1, 1), np.uint8), iterations=1)\n",
    "            \n",
    "            word_edges = cv2.Canny(word, 30, 150)\n",
    "            \n",
    "            kernel_char = np.ones((15, 2), np.uint8)\n",
    "            dilated_char = cv2.dilate(word_edges, kernel_char, iterations=1)\n",
    "            cv2.imshow('dilated_char', dilated_char)\n",
    "            cv2.waitKey(0)\n",
    "            \n",
    "            im2, ctrs_char, hier = cv2.findContours(dilated_char.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            sorted_ctrs_char = sorted(ctrs_char, key=lambda ctr: cv2.boundingRect(ctr)[0])\n",
    "            \n",
    "            character_list = []\n",
    "            \n",
    "            for i, ctr_char in enumerate(sorted_ctrs_char):\n",
    "                char_x, char_y, char_w, char_h = cv2.boundingRect(ctr_char)\n",
    "                charac = cropImage(char_x, char_y, char_w, char_h, word)\n",
    "                cv2.imshow('characsadsadasdasd', charac)\n",
    "                cv2.waitKey(0)\n",
    "                \n",
    "                character = prediction(charac)\n",
    "                character_list.append(character)\n",
    "            correctedword = \"\".join(character_list)\n",
    "            word_list.append(correctedword)\n",
    "    recognized_text = \" \".join(word_list)\n",
    "    print(\" \".join(word_list))\n",
    "    #print(recognized_text)\n",
    "        \n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def words(text):\n",
    "\treturn re.findall(r'\\w+', text.lower())\n",
    "\n",
    "WORDS = Counter(words(open('./data/all_vocal_books.txt', encoding='utf-8').read()))\n",
    "\n",
    "def P(word, N=sum(WORDS.values())):\n",
    "    \"Probability of `word`.\"\n",
    "    return WORDS[word] / N\n",
    "\n",
    "def correction(word):\n",
    "    \"Most probable spelling correction for word.\"\n",
    "    return max(candidates(word), key=P)\n",
    "\n",
    "def candidates(word):\n",
    "    \"Generate possible spelling corrections for word.\"\n",
    "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
    "\n",
    "def known(words):\n",
    "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "    return set(w for w in words if w in WORDS)\n",
    "\n",
    "def edits1(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    letters    = '0123456789abcdefghijklmnopqrstuvwxyz'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def edits2(word):\n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
