{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Praneet\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.preprocessing import image as im\n",
    "from keras import backend as k\n",
    "import tensorflow as tf\n",
    "import pytesseract as tesseract\n",
    "tf.reset_default_graph()\n",
    "from keras.models import load_model\n",
    "model=load_model('finalbestmodel.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get tags from non-filled image\n",
    "def traverseCroppedSections():\n",
    "    labelList = []\n",
    "    for x, y, w, h in coordinates:\n",
    "        croppedSection = cropImage(x, y, w, h, nonfilledtesseract)\n",
    "        label = tesseract.image_to_string(croppedSection)\n",
    "        labelList.append(label)\n",
    "    print(labelList)\n",
    "    # push these labels to database along with the coordinates and index\n",
    "    \n",
    "# Cropping the image\n",
    "def cropImage(x, y, w, h, image):\n",
    "    # Crop image here\n",
    "    croppedImage = image[y:y + h,x:x + w]\n",
    "    return croppedImage\n",
    "\n",
    "# function to match template\n",
    "def templateMatching(wholeimage, template):\n",
    "    result = cv2.matchTemplate(wholeimage, template, cv2.TM_CCOEFF)\n",
    "    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\n",
    "    return max_loc[0], max_loc[1]\n",
    "\n",
    "def makeSquare(not_square):\n",
    "    # Adds black pixels as padding\n",
    "    \n",
    "    BLACK = [0, 0, 0]\n",
    "    img_dim = not_square.shape\n",
    "    height = img_dim[0]\n",
    "    width = img_dim[1]\n",
    "    if (height == width):\n",
    "        square = not_square\n",
    "        return square\n",
    "    else:\n",
    "        doublesize = cv2.resize(not_square, (2 * width, 2 * height), interpolation = cv2.INTER_CUBIC)\n",
    "        height = height * 2\n",
    "        width = width * 2\n",
    "        if (height > width):\n",
    "            pad = (height - width)/2\n",
    "            pad = int(pad)\n",
    "            #doublesize = int(doublesize)\n",
    "            doublesize_square = cv2.copyMakeBorder(doublesize, 0, 0, pad,\\\n",
    "                                                  pad, cv2.BORDER_CONSTANT, value = BLACK)\n",
    "        else:\n",
    "            pad = (width - height)/2\n",
    "            pad = int(pad)\n",
    "            doublesize_square = cv2.copyMakeBorder(doublesize, pad, pad, 0, 0,\\\n",
    "                                                  cv2.BORDER_CONSTANT, value = BLACK)\n",
    "    doublesize_square_dim = doublesize_square.shape\n",
    "    return doublesize_square\n",
    "\n",
    "def resize_to_pixel(dimensions, image):\n",
    "    \n",
    "    buffer_pix = 4\n",
    "    dimensions = dimensions - buffer_pix\n",
    "    squared = image\n",
    "    r = float(dimensions)/squared.shape[1]\n",
    "    dim = (dimensions, int(squared.shape[0] * r))\n",
    "    resized = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)\n",
    "    img_dim2 = resized.shape\n",
    "    height_r = img_dim2[0]\n",
    "    widht_r = img_dim2[1]\n",
    "    BLACK = [0, 0, 0]\n",
    "    if (height_r > widht_r):\n",
    "        resized = cv2.copyMakeBorder(resized, 0, 0, 0, 1, cv2.BORDER_CONSTANT, value = BLACK)\n",
    "    if (height_r < widht_r):\n",
    "        resized = cv2.copyMakeBorder(resized, 1, 0, 0, 0, cv2.BORDER_CONSTANT, value = BLACK)\n",
    "    p = 2\n",
    "    ReSizedImg = cv2.copyMakeBorder(resized, p, p, p, p, cv2.BORDER_CONSTANT, value = BLACK)\n",
    "    img_dim = ReSizedImg.shape\n",
    "    height = img_dim[0]\n",
    "    width = img_dim[1]\n",
    "    return ReSizedImg\n",
    "\n",
    "\n",
    "def prediction(char_image):\n",
    "    squared = makeSquare(char_image)\n",
    "    size28 = resize_to_pixel(28, squared)\n",
    "    cv2.imshow('char resized', size28)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()     \n",
    "    predict_img = im.img_to_array(size28)\n",
    "    predict_img = np.expand_dims(predict_img, axis = 0)\n",
    "    predictedarray = model.predict(predict_img)\n",
    "    index = calculateClass(predictedarray[0])\n",
    "    \n",
    "    predicted_class = label_dictionary[index]\n",
    "    return predicted_class\n",
    "\n",
    "def calculateClass(predictedarray):\n",
    "    predictedclass = 0\n",
    "    predictedclassindex = 0\n",
    "    index = 0\n",
    "    for classprediction in predictedarray:\n",
    "        if classprediction > predictedclass:\n",
    "            predictedclass = classprediction\n",
    "            predictedclassindex = index\n",
    "        index = index + 1\n",
    "    return predictedclassindex\n",
    "\n",
    "# cropping and setdifferencing function\n",
    "def getNonfilledCroppedSections(coordinates):\n",
    "    i = 0\n",
    "    for x, y, w, h in coordinates:\n",
    "        \n",
    "        tag = tags[i]\n",
    "        i = i + 1\n",
    "        \n",
    "        # cropping non filled image\n",
    "        nonfilledcroppedsection = cropImage(x, y, w, h, nonfilledimage)\n",
    "        cv2.imshow('nonfilledcroppedsection', nonfilledcroppedsection)\n",
    "        cv2.waitKey(0)\n",
    "        \n",
    "        #dilating \n",
    "        nonfilledcroppedsectiondilated = cropImage(x, y, w, h, nonfilledimagedilated)\n",
    "        \n",
    "        crop_h = nonfilledcroppedsection.shape[0]\n",
    "        crop_w = nonfilledcroppedsection.shape[1]\n",
    "        \n",
    "        buffer_x = x - 75\n",
    "        buffer_y = y - 75\n",
    "        buffer_w = w + 2*75\n",
    "        buffer_h = h + 2*75\n",
    "        \n",
    "        if ( buffer_x < 0 ):\n",
    "            buffer_x = 0\n",
    "        if ( buffer_y < 0 ):\n",
    "            buffer_y = 0\n",
    "        if ( buffer_x + buffer_w > filledimage.shape[0] ):\n",
    "            buffer_w = filledimage.shape[0]\n",
    "        if ( buffer_y + buffer_h > filledimage.shape[1] ):\n",
    "            buffer_h = filledimage.shape[1]\n",
    "            \n",
    "        filledcroppedsectionbuffer = cropImage(buffer_x, buffer_y, buffer_w, buffer_h, filledimagedilated)\n",
    "        cv2.imshow('filledcroppedsectionbuffer', filledcroppedsectionbuffer)\n",
    "        cv2.waitKey(0)\n",
    "        \n",
    "        # To use for set difference\n",
    "        filledcroppedsectionbuffernondilated = cropImage(buffer_x, buffer_y, buffer_w, buffer_h, filledimage)\n",
    "        \n",
    "        #crop_x, crop_y = templateMatching(filledcroppedsectionbuffer, nonfilledcroppedsection)\n",
    "        crop_x, crop_y = templateMatching(filledcroppedsectionbuffernondilated, nonfilledcroppedsection)\n",
    "        \n",
    "        # cropping the matched template from filled image\n",
    "        filledcroppedsection = cropImage(buffer_x + crop_x, buffer_y + crop_y, crop_w, crop_h, filledimage)\n",
    "        cv2.imshow('filledcroppedsection', filledcroppedsection)\n",
    "        cv2.waitKey(0)\n",
    "        \n",
    "        # subtracting nonfilled image from filled image\n",
    "        setDifference = np.subtract(filledcroppedsection, nonfilledcroppedsection)\n",
    "        cv2.imshow('setDifference', setDifference)\n",
    "        cv2.waitKey(0)\n",
    "        \n",
    "        setDifference = cv2.medianBlur(setDifference, 3)\n",
    "        #setDifference = cv2.erode(setDifference, np.ones((3, 3), np.uint8), iterations=1)\n",
    "        cv2.imshow('setDifferenceeroded', setDifference)\n",
    "        cv2.waitKey(0)\n",
    "        \n",
    "        converted_to_text = ocr(setDifference)\n",
    "        print(tag + ' : ' + converted_to_text)\n",
    "        \n",
    "        \n",
    "def ocr(image):\n",
    "    \n",
    "    # detecting edges in the image\n",
    "    image_edges = cv2.Canny(image, 30, 150)\n",
    "    \n",
    "    # dilating image to detect individual lines\n",
    "    kernel_line = np.ones((10, 80), np.uint8)\n",
    "    dilated_line = cv2.dilate(image_edges, kernel_line, iterations=1)\n",
    "    \n",
    "    # finding contours of the line\n",
    "    im2, ctrs_line, hier = cv2.findContours(dilated_line.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    sorted_ctrs_line = sorted(ctrs_line, key=lambda ctr: cv2.boundingRect(ctr)[1])\n",
    "    \n",
    "    # list of words\n",
    "    word_list = []\n",
    "    \n",
    "    for i, ctr_line in enumerate(sorted_ctrs_line):\n",
    "        # getting coordinates of the line contour\n",
    "        line_x, line_y, line_w, line_h = cv2.boundingRect(ctr_line)\n",
    "        \n",
    "        # if condition for removing unnecessary contours\n",
    "        if line_w * line_h < 10000:\n",
    "            continue\n",
    "        \n",
    "        line = cropImage(line_x, line_y, line_w, line_h, image)\n",
    "        cv2.imshow('line', line)\n",
    "        cv2.waitKey(0)\n",
    "        \n",
    "        # detecting edges in the image\n",
    "        line_edges = cv2.Canny(line, 30, 150)\n",
    "        \n",
    "        # dilating line to detect individual words\n",
    "        kernel_word = np.ones((10, 60), np.uint8)\n",
    "        dilated_word = cv2.dilate(line_edges, kernel_word, iterations=1)\n",
    "        \n",
    "        # finding contours of the word\n",
    "        im2, ctrs_word, hier = cv2.findContours(dilated_word.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        sorted_ctrs_word = sorted(ctrs_word, key=lambda ctr: cv2.boundingRect(ctr)[0])\n",
    "        \n",
    "        for i, ctr_word in enumerate(sorted_ctrs_word):\n",
    "            # getting coordinates of the word contour\n",
    "            word_x, word_y, word_w, word_h = cv2.boundingRect(ctr_word)\n",
    "            \n",
    "            # if condition for removing unnecessary contours\n",
    "            if word_w * word_h < 2500:\n",
    "                continue\n",
    "            \n",
    "            #print(\"Word \" + str(word_x), str(word_y), str(word_w), str(word_h))\n",
    "            \n",
    "            word = cropImage(word_x, word_y, word_w, word_h, line)\n",
    "            cv2.imshow('word', word)\n",
    "            cv2.waitKey(0)\n",
    "            word = cv2.erode(word, np.ones((1, 1), np.uint8), iterations=1)\n",
    "            \n",
    "            # detecting edges in the image\n",
    "            word_edges = cv2.Canny(word, 30, 150)\n",
    "            \n",
    "            # dilating word to detect individual characters\n",
    "            kernel_char = np.ones((15, 5), np.uint8)\n",
    "            dilated_char = cv2.dilate(word_edges, kernel_char, iterations=1)\n",
    "            cv2.imshow('dilated_char', dilated_char)\n",
    "            cv2.waitKey(0)\n",
    "            \n",
    "            # finding contours of the characters\n",
    "            im2, ctrs_char, hier = cv2.findContours(dilated_char.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            sorted_ctrs_char = sorted(ctrs_char, key=lambda ctr: cv2.boundingRect(ctr)[0])\n",
    "            \n",
    "            # list of words\n",
    "            character_list = []\n",
    "            \n",
    "            for i, ctr_char in enumerate(sorted_ctrs_char):\n",
    "                # getting coordinates of the character contour\n",
    "                char_x, char_y, char_w, char_h = cv2.boundingRect(ctr_char)\n",
    "                \n",
    "                # if condition for removing unnecessary contours\n",
    "                if char_w * char_h < 180:\n",
    "                    continue\n",
    "                    \n",
    "                #print(\"Character \" + str(char_x), str(char_y), str(char_w), str(char_h))\n",
    "                \n",
    "                charac = cropImage(char_x, char_y, char_w, char_h, word)\n",
    "                cv2.imshow('charac', charac)\n",
    "                cv2.waitKey(0)\n",
    "                cv2.destroyAllWindows()\n",
    "                \n",
    "                character = prediction(charac)\n",
    "                character_list.append(character)\n",
    "            word_list.append(\"\".join(character_list))\n",
    "    recognized_text = \" \".join(word_list)\n",
    "    return recognized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre Enrolment ID : EKP9612\n",
      "Full Name: : 84UM1T M1VAREKAR\n",
      "House No BIdg Apt : CUdd4R0AB\n",
      "PINCODE : 40C61Z\n"
     ]
    }
   ],
   "source": [
    "# Pran nonfilled\n",
    "nonfilledimage = cv2.imread('nonfilledaadhar.jpg',0)\n",
    "\n",
    "# IELTS nonfilled\n",
    "#nonfilledimage = cv2.imread('nonfilled_0.jpg',0)\n",
    "\n",
    "nonfilledimage = cv2.threshold(nonfilledimage, 100, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "nonfilledtesseract = nonfilledimage\n",
    "\n",
    "nonfilledimagedilated = nonfilledimage.copy()\n",
    "nonfilledimagedilated = cv2.dilate(nonfilledimagedilated, np.ones((2, 2), np.uint8), iterations=4)\n",
    "nonfilledimage = nonfilledimagedilated\n",
    "\n",
    "# Pran filled\n",
    "filledimage = cv2.imread('filledaadhar.jpg',0)\n",
    "\n",
    "# IELTS filled\n",
    "#filledimage = cv2.imread('filled_0.jpg',0)\n",
    "\n",
    "filledimage = cv2.threshold(filledimage, 100, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "filledimagedilated = cv2.dilate(filledimage, np.ones((2, 2), np.uint8), iterations=4)\n",
    "\n",
    "# PRAN\n",
    "#coordinates = [[196,336,1656,119],[191,981,2137,94],[920,2999,620,119],[176,1298,977,128]]\n",
    "# aadhar\n",
    "coordinates = [[243,585,951,89],[237,679,2003,79],[242,962,927,84],[1750,1309,515,89]]\n",
    "\n",
    "label_dictionary = {0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '9', 10: 'a',\n",
    "                    11: 'b', 12: 'd', 13: 'e', 14: 'f', 15: 'g', 16: 'h', 17: 'i', 18: 'j', 19: 'l', 20: 'm',\n",
    "                    21: 'n', 22: 'q', 23: 'r', 24: 't', 25: 'y', 26: 'A', 27: 'B', 28: 'C', 29: 'D', 30: 'E',\n",
    "                    31: 'F', 32: 'G', 33: 'H', 34: 'I', 35: 'J', 36: 'K', 37: 'L', 38: 'M', 39: 'N', 40: 'O',\n",
    "                    41: 'P', 42: 'Q', 43: 'R', 44: 'S', 45: 'T', 46: 'U', 47: 'V', 48: 'W', 49: 'X', 50: 'Y',\n",
    "                    51: 'Z'}\n",
    "\n",
    "# pran tags\n",
    "#tags = ['Acknowledge No','First Name','Phone No','DOB']\n",
    "# aadhar tags\n",
    "tags = ['Pre Enrolment ID','Full Name:','House No BIdg Apt','PINCODE']\n",
    "               \n",
    "#tags_index = 0\n",
    "\n",
    "getNonfilledCroppedSections(coordinates)\n",
    "#traverseCroppedSections()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
