{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Praneet\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.preprocessing import image as im\n",
    "from keras import backend as k\n",
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "model=load_model('finalbestmodel.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def traverseCroppedSections():\n",
    "    labelList = []\n",
    "    for x, y, w, h in coordinates:\n",
    "        croppedSection = cropImage(x, y, w, h, nonfilledimage)\n",
    "        #label = tesseract.image_to_string(croppedSection)\n",
    "        #labelList.append(label)\n",
    "    # push these labels to database along with the coordinates and index\n",
    "\n",
    "def cropImage(x, y, w, h, image):\n",
    "    # Crop image here\n",
    "    croppedImage = image[y:y + h,x:x + w]\n",
    "    return croppedImage\n",
    "\n",
    "# crop nonfilled\n",
    "def getNonfilledCroppedSections(coordinates):\n",
    "    for x, y, w, h in coordinates:\n",
    "        nonfilledcroppedsection = cropImage(x, y, w, h, nonfilledimage)\n",
    "        height = nonfilledcroppedsection.shape[0]\n",
    "        width = nonfilledcroppedsection.shape[1]\n",
    "        result = cv2.matchTemplate(filledimage, nonfilledcroppedsection, cv2.TM_CCOEFF)\n",
    "        min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\n",
    "        crop_x, crop_y, crop_w, crop_h = max_loc[0], max_loc[1], width, height\n",
    "        filledcroppedsection = cropImage(crop_x, crop_y, crop_w, crop_h, filledimage)\n",
    "        setDifference = np.subtract(filledcroppedsection, nonfilledcroppedsection)\n",
    "        converted_to_text = ocr(setDifference)\n",
    "        print(converted_to_text)\n",
    "        \n",
    "def ocr(image):\n",
    "    kernel_line = np.ones((10, 80), np.uint8)\n",
    "    dilated_line = cv2.dilate(image, kernel_line, iterations=1)\n",
    "    \n",
    "    im2, ctrs_line, hier = cv2.findContours(dilated_line.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    sorted_ctrs_line = sorted(ctrs_line, key=lambda ctr: cv2.boundingRect(ctr)[1])\n",
    "    word_list = []\n",
    "    \n",
    "    for i, ctr_line in enumerate(sorted_ctrs_line):\n",
    "        line_x, line_y, line_w, line_h = cv2.boundingRect(ctr_line)\n",
    "        # if condition for too small contours\n",
    "        if line_w * line_h > 115:\n",
    "            line = image[line_y:line_y + line_h, line_x:line_x + line_w]\n",
    "            cv2.imshow('Non Filled', line)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()        \n",
    "            kernel_word = np.ones((10, 15), np.uint8)\n",
    "            dilated_word = cv2.dilate(line, kernel_word, iterations=1)\n",
    "\n",
    "            im2, ctrs_word, hier = cv2.findContours(dilated_word.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            sorted_ctrs_word = sorted(ctrs_word, key=lambda ctr: cv2.boundingRect(ctr)[1])\n",
    "\n",
    "            for i, ctr_word in enumerate(sorted_ctrs_word):\n",
    "                word_x, word_y, word_w, word_h = cv2.boundingRect(ctr_word)\n",
    "                # if condition for too small contours\n",
    "                if word_w * word_h > 115:\n",
    "                    word = line[word_y:word_y + word_h, word_x:word_x + word_w]\n",
    "                    cv2.imshow('Non Filled', word)\n",
    "                    cv2.waitKey(0)\n",
    "                    cv2.destroyAllWindows()            \n",
    "                    kernel_char = np.ones((10, 1), np.uint8)\n",
    "                    dilated_char = cv2.dilate(word, kernel_char, iterations=1)\n",
    "\n",
    "                    im2, ctrs_char, hier = cv2.findContours(dilated_char.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                    sorted_ctrs_char = sorted(ctrs_char, key=lambda ctr: cv2.boundingRect(ctr)[1])\n",
    "\n",
    "                    character_list = []\n",
    "\n",
    "                    for i, ctr_char in enumerate(sorted_ctrs_char):\n",
    "                        char_x, char_y, char_w, char_h = cv2.boundingRect(ctr_char)\n",
    "                        char = word[word_y:word_y + word_h, word_x:word_x + word_w]\n",
    "                        #character = prediction(char)\n",
    "                        #character_list.append(character)\n",
    "\n",
    "                    #word_list.append(\"\".join(character_list))\n",
    "    #recognized_text = \" \".join(word_list)\n",
    "    return \"recognized_text\"\n",
    "                \n",
    "def prediction(char_image):\n",
    "    squared = makeSquare(char_image)\n",
    "    size28 = resize_to_pixel(28, squared)\n",
    "    predict_img = im.img_to_array(size28)\n",
    "    predict_img = np.expand_dims(predict_img, axis = 0)\n",
    "    predictedarray = model.predict(predict_img)\n",
    "    \n",
    "    top_values, top_indices = k.get_session().run(tf.nn.top_k(model.predict_proba(predict_img), k=3))\n",
    "    predicted_class = label_dictionary[top_indices[0]]\n",
    "    return predicted_class\n",
    "\n",
    "# match that nonfilled cropped template in filled ***************************************** done\n",
    "# crop the matched template from filled ***************************************** done\n",
    "# apply set difference between nonfilled template and filled template ***************************************** done\n",
    "# check for contours in setdifferenced template ***************************************** done\n",
    "## line detection ***************************************** done\n",
    "## word detection ***************************************** done\n",
    "## predict characters ***************************************** done\n",
    "## return word\n",
    "## return wordlist\n",
    "# make key value pair of label and word list\n",
    "\n",
    "def makeSquare(not_square):\n",
    "    # Adds black pixels as padding\n",
    "    \n",
    "    BLACK = [0, 0, 0]\n",
    "    img_dim = not_square.shape\n",
    "    height = img_dim[0]\n",
    "    width = img_dim[1]\n",
    "    if (height == width):\n",
    "        square = not_square\n",
    "        return square\n",
    "    else:\n",
    "        doublesize = cv2.resize(not_square, (2 * width, 2 * height), interpolation = cv2.INTER_CUBIC)\n",
    "        height = height * 2\n",
    "        width = width * 2\n",
    "        if (height > width):\n",
    "            pad = (height - width)/2\n",
    "            pad = int(pad)\n",
    "            #doublesize = int(doublesize)\n",
    "            doublesize_square = cv2.copyMakeBorder(doublesize, 0, 0, pad,\\\n",
    "                                                  pad, cv2.BORDER_CONSTANT, value = BLACK)\n",
    "        else:\n",
    "            pad = (width - height)/2\n",
    "            pad = int(pad)\n",
    "            doublesize_square = cv2.copyMakeBorder(doublesize, pad, pad, 0, 0,\\\n",
    "                                                  cv2.BORDER_CONSTANT, value = BLACK)\n",
    "    doublesize_square_dim = doublesize_square.shape\n",
    "    return doublesize_square\n",
    "\n",
    "def resize_to_pixel(dimensions, image):\n",
    "    \n",
    "    buffer_pix = 4\n",
    "    dimensions = dimensions - buffer_pix\n",
    "    squared = image\n",
    "    r = float(dimensions)/squared.shape[1]\n",
    "    dim = (dimensions, int(squared.shape[0] * r))\n",
    "    resized = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)\n",
    "    img_dim2 = resized.shape\n",
    "    height_r = img_dim2[0]\n",
    "    widht_r = img_dim2[1]\n",
    "    BLACK = [0, 0, 0]\n",
    "    if (height_r > widht_r):\n",
    "        resized = cv2.copyMakeBorder(resized, 0, 0, 0, 1, cv2.BORDER_CONSTANT, value = BLACK)\n",
    "    if (height_r < widht_r):\n",
    "        resized = cv2.copyMakeBorder(resized, 1, 0, 0, 0, cv2.BORDER_CONSTANT, value = BLACK)\n",
    "    p = 2\n",
    "    ReSizedImg = cv2.copyMakeBorder(resized, p, p, p, p, cv2.BORDER_CONSTANT, value = BLACK)\n",
    "    img_dim = ReSizedImg.shape\n",
    "    height = img_dim[0]\n",
    "    width = img_dim[1]\n",
    "    return ReSizedImg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text\n",
      "recognized_text\n",
      "recognized_text\n",
      "recognized_text\n",
      "recognized_text\n",
      "recognized_text\n"
     ]
    }
   ],
   "source": [
    "nonfilledimage = cv2.imread('nonfilled.jpg',0)\n",
    "#nonfilledimage = cv2.bitwise_not(nonfilledimage)\n",
    "nonfilledimage = cv2.threshold(nonfilledimage, 100, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "cv2.imshow('Non Filled', nonfilledimage)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "filledimage = cv2.imread('filled.jpg',0)\n",
    "#filledimage = cv2.bitwise_not(filledimage)\n",
    "filledimage = cv2.threshold(filledimage, 100, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "cv2.imshow('Filled', filledimage)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "coordinates = [[101,464,1000,44],[90,621,448,44],[557,623,448,49],[92,541,1017,56],[94,1383,423,37],[438,1416,287,53]]\n",
    "\n",
    "label_dictionary = {0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '9', 10: 'a',\n",
    "                    11: 'b', 12: 'd', 13: 'e', 14: 'f', 15: 'g', 16: 'h', 17: 'i', 18: 'j', 19: 'l', 20: 'm',\n",
    "                    21: 'n', 22: 'q', 23: 'r', 24: 't', 25: 'y', 26: 'A', 27: 'B', 28: 'C', 29: 'D', 30: 'E',\n",
    "                    31: 'F', 32: 'G', 33: 'H', 34: 'I', 35: 'J', 36: 'K', 37: 'L', 38: 'M', 39: 'N', 40: 'O',\n",
    "                    41: 'P', 42: 'Q', 43: 'R', 44: 'S', 45: 'T', 46: 'U', 47: 'V', 48: 'W', 49: 'X', 50: 'Y',\n",
    "                    51: 'Z'}\n",
    "getNonfilledCroppedSections(coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '9', 10: 'a', 11: 'b', 12: 'd', 13: 'e', 14: 'f', 15: 'g', 16: 'h', 17: 'i', 18: 'j', 19: 'l', 20: 'm', 21: 'n', 22: 'q', 23: 'r', 24: 't', 25: 'y', 26: 'A', 27: 'B', 28: 'C', 29: 'D', 30: 'E', 31: 'F', 32: 'G', 33: 'H', 34: 'I', 35: 'J', 36: 'K', 37: 'L', 38: 'M', 39: 'N', 40: 'O', 41: 'P', 42: 'Q', 43: 'R', 44: 'S', 45: 'T', 46: 'U', 47: 'V', 48: 'W', 49: 'X', 50: 'Y', 51: 'Z'}\n"
     ]
    }
   ],
   "source": [
    "label_dictionary = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'b', 'd', 'e', 'f',\n",
    "                    'g', 'h', 'i', 'j', 'l', 'm', 'n', 'q', 'r', 't', 'y', 'A', 'B', 'C', 'D',\n",
    "                    'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q',\n",
    "                    'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n",
    "labels = {}\n",
    "i = 0\n",
    "for label in label_dictionary:\n",
    "    labels[i] = label\n",
    "    i = i + 1\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
