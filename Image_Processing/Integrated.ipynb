{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.preprocessing import image as im\n",
    "from keras import backend as k\n",
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "model=load_model('finalbestmodel.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def traverseCroppedSections():\n",
    "    labelList = []\n",
    "    for x, y, w, h in coordinates:\n",
    "        croppedSection = cropImage(x, y, w, h, nonfilledimage)\n",
    "        #label = tesseract.image_to_string(croppedSection)\n",
    "        #labelList.append(label)\n",
    "    # push these labels to database along with the coordinates and index\n",
    "\n",
    "def cropImage(x, y, w, h, image):\n",
    "    # Crop image here\n",
    "    croppedImage = image[y:y + h,x:x + w]\n",
    "    return croppedImage\n",
    "\n",
    "# crop nonfilled\n",
    "def getNonfilledCroppedSections(coordinates):\n",
    "    for x, y, w, h in coordinates:\n",
    "        nonfilledcroppedsection = cropImage(x, y, w, h, nonfilledimage)\n",
    "        nonfilledcroppedsectiondilated = cropImage(x, y, w, h, nonfilledimage)\n",
    "        height = nonfilledcroppedsection.shape[0]\n",
    "        width = nonfilledcroppedsection.shape[1]\n",
    "        #filledimage = cv2.erode(filledimage, np.ones((1, 1), np.uint8), iterations=1)\n",
    "        result = cv2.matchTemplate(filledimage, nonfilledcroppedsection, cv2.TM_CCOEFF)\n",
    "        min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\n",
    "        crop_x, crop_y, crop_w, crop_h = max_loc[0], max_loc[1], width, height\n",
    "        filledcroppedsection = cropImage(crop_x, crop_y, crop_w, crop_h, filledimage)\n",
    "        #filledcroppedsection = cv2.erode(filledcroppedsection, np.ones((1, 1), np.uint8), iterations=1)\n",
    "        setDifference = np.subtract(filledcroppedsection, nonfilledcroppedsectiondilated)\n",
    "        setDifference = cv2.erode(setDifference, np.ones((2, 2), np.uint8), iterations=1)\n",
    "        converted_to_text = ocr(setDifference)\n",
    "        print(converted_to_text)\n",
    "        \n",
    "def ocr(image):\n",
    "    kernel_line = np.ones((10, 80), np.uint8)\n",
    "    dilated_line = cv2.dilate(image, kernel_line, iterations=1)\n",
    "    \n",
    "    im2, ctrs_line, hier = cv2.findContours(dilated_line.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    sorted_ctrs_line = sorted(ctrs_line, key=lambda ctr: cv2.boundingRect(ctr)[1])\n",
    "    word_list = []\n",
    "    \n",
    "    for i, ctr_line in enumerate(sorted_ctrs_line):\n",
    "        line_x, line_y, line_w, line_h = cv2.boundingRect(ctr_line)\n",
    "        # if condition for too small contours\n",
    "        if line_w * line_h < 2000:\n",
    "            continue\n",
    "        #print(line_w * line_h)\n",
    "        #print(\"Line\")\n",
    "        line = image[line_y:line_y + line_h, line_x:line_x + line_w]\n",
    "        kernel_word = np.ones((10, 55), np.uint8)\n",
    "        \n",
    "        #cv2.imshow('Line eroded', eroded_line)\n",
    "        #cv2.waitKey(0)\n",
    "        #cv2.destroyAllWindows()        \n",
    "\n",
    "        dilated_word = cv2.dilate(line, kernel_word, iterations=1)\n",
    "        #cv2.imshow('Line dilated', dilated_word)\n",
    "        #cv2.waitKey(0)\n",
    "        #cv2.destroyAllWindows()        \n",
    "\n",
    "        im2, ctrs_word, hier = cv2.findContours(dilated_word.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        sorted_ctrs_word = sorted(ctrs_word, key=lambda ctr: cv2.boundingRect(ctr)[0])\n",
    "\n",
    "        for i, ctr_word in enumerate(sorted_ctrs_word):\n",
    "            word_x, word_y, word_w, word_h = cv2.boundingRect(ctr_word)\n",
    "            # if condition for too small contours\n",
    "            if word_w * word_h < 2500:\n",
    "                continue\n",
    "            #print(word_w * word_h)\n",
    "            #print(\"Word\")\n",
    "            word = line[word_y:word_y + word_h, word_x:word_x + word_w]\n",
    "            cv2.imshow('Word', word)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()            \n",
    "            kernel_char = np.ones((10, 1), np.uint8)\n",
    "            #eroded_word = cv2.erode(word, np.ones((2, 2), np.uint8), iterations=1)\n",
    "            dilated_char = cv2.dilate(word, kernel_char, iterations=1)\n",
    "\n",
    "            im2, ctrs_char, hier = cv2.findContours(dilated_char.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            sorted_ctrs_char = sorted(ctrs_char, key=lambda ctr: cv2.boundingRect(ctr)[1])\n",
    "\n",
    "            character_list = []\n",
    "\n",
    "            for i, ctr_char in enumerate(sorted_ctrs_char):\n",
    "                char_x, char_y, char_w, char_h = cv2.boundingRect(ctr_char)\n",
    "                char = word[word_y:word_y + word_h, word_x:word_x + word_w]\n",
    "                character = prediction(char)\n",
    "                character_list.append(character)\n",
    "\n",
    "            word_list.append(\"\".join(character_list))\n",
    "    recognized_text = \" \".join(word_list)\n",
    "    return recognized_text\n",
    "                \n",
    "def prediction(char_image):\n",
    "    squared = makeSquare(char_image)\n",
    "    size28 = resize_to_pixel(28, squared)\n",
    "    cv2.imshow('Word', size28)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()     \n",
    "    predict_img = im.img_to_array(size28)\n",
    "    predict_img = np.expand_dims(predict_img, axis = 0)\n",
    "    predictedarray = model.predict(predict_img)\n",
    "    index = calculateClass(predictedarray[0])\n",
    "    \n",
    "    predicted_class = label_dictionary[index]\n",
    "    return predicted_class\n",
    "\n",
    "def calculateClass(predictedarray):\n",
    "    predictedclass = 0\n",
    "    predictedclassindex = 0\n",
    "    index = 0\n",
    "    for classprediction in predictedarray:\n",
    "        if classprediction > predictedclass:\n",
    "            predictedclass = classprediction\n",
    "            predictedclassindex = index\n",
    "        index = index + 1\n",
    "    return predictedclassindex\n",
    "\n",
    "# match that nonfilled cropped template in filled ***************************************** done\n",
    "# crop the matched template from filled ***************************************** done\n",
    "# apply set difference between nonfilled template and filled template ***************************************** done\n",
    "# check for contours in setdifferenced template ***************************************** done\n",
    "## line detection ***************************************** done\n",
    "## word detection ***************************************** done\n",
    "## predict characters ***************************************** done\n",
    "## return word\n",
    "## return wordlist\n",
    "# make key value pair of label and word list\n",
    "\n",
    "def makeSquare(not_square):\n",
    "    # Adds black pixels as padding\n",
    "    \n",
    "    BLACK = [0, 0, 0]\n",
    "    img_dim = not_square.shape\n",
    "    height = img_dim[0]\n",
    "    width = img_dim[1]\n",
    "    if (height == width):\n",
    "        square = not_square\n",
    "        return square\n",
    "    else:\n",
    "        doublesize = cv2.resize(not_square, (2 * width, 2 * height), interpolation = cv2.INTER_CUBIC)\n",
    "        height = height * 2\n",
    "        width = width * 2\n",
    "        if (height > width):\n",
    "            pad = (height - width)/2\n",
    "            pad = int(pad)\n",
    "            #doublesize = int(doublesize)\n",
    "            doublesize_square = cv2.copyMakeBorder(doublesize, 0, 0, pad,\\\n",
    "                                                  pad, cv2.BORDER_CONSTANT, value = BLACK)\n",
    "        else:\n",
    "            pad = (width - height)/2\n",
    "            pad = int(pad)\n",
    "            doublesize_square = cv2.copyMakeBorder(doublesize, pad, pad, 0, 0,\\\n",
    "                                                  cv2.BORDER_CONSTANT, value = BLACK)\n",
    "    doublesize_square_dim = doublesize_square.shape\n",
    "    return doublesize_square\n",
    "\n",
    "def resize_to_pixel(dimensions, image):\n",
    "    \n",
    "    buffer_pix = 4\n",
    "    dimensions = dimensions - buffer_pix\n",
    "    squared = image\n",
    "    r = float(dimensions)/squared.shape[1]\n",
    "    dim = (dimensions, int(squared.shape[0] * r))\n",
    "    resized = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)\n",
    "    img_dim2 = resized.shape\n",
    "    height_r = img_dim2[0]\n",
    "    widht_r = img_dim2[1]\n",
    "    BLACK = [0, 0, 0]\n",
    "    if (height_r > widht_r):\n",
    "        resized = cv2.copyMakeBorder(resized, 0, 0, 0, 1, cv2.BORDER_CONSTANT, value = BLACK)\n",
    "    if (height_r < widht_r):\n",
    "        resized = cv2.copyMakeBorder(resized, 1, 0, 0, 0, cv2.BORDER_CONSTANT, value = BLACK)\n",
    "    p = 2\n",
    "    ReSizedImg = cv2.copyMakeBorder(resized, p, p, p, p, cv2.BORDER_CONSTANT, value = BLACK)\n",
    "    img_dim = ReSizedImg.shape\n",
    "    height = img_dim[0]\n",
    "    width = img_dim[1]\n",
    "    return ReSizedImg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "777777777 iiiiiiiiiiiii\n",
      "7777777777777777777777777777777777\n",
      "WW WWWWWWWW\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "..\\..\\..\\modules\\imgproc\\src\\imgwarp.cpp:3229: error: (-215) ssize.area() > 0 in function cv::resize\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-f943ecf57260>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m                     \u001b[1;36m41\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'P'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m42\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'Q'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m43\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'R'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m44\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'S'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m45\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'T'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m46\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'U'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m47\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'V'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m48\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'W'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m49\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'X'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'Y'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                     51: 'Z'}\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mgetNonfilledCroppedSections\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcoordinates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-53-8db68bda5738>\u001b[0m in \u001b[0;36mgetNonfilledCroppedSections\u001b[0;34m(coordinates)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0msetDifference\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubtract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilledcroppedsection\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnonfilledcroppedsectiondilated\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0msetDifference\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msetDifference\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mconverted_to_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mocr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msetDifference\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconverted_to_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-53-8db68bda5738>\u001b[0m in \u001b[0;36mocr\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0mchar_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchar_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchar_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchar_h\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mboundingRect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctr_char\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0mchar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mword_y\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mword_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword_x\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mword_x\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mword_w\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m                 \u001b[0mcharacter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m                 \u001b[0mcharacter_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcharacter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-53-8db68bda5738>\u001b[0m in \u001b[0;36mprediction\u001b[0;34m(char_image)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchar_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m     \u001b[0msquared\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmakeSquare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchar_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m     \u001b[0msize28\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresize_to_pixel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msquared\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Word'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize28\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-53-8db68bda5738>\u001b[0m in \u001b[0;36mmakeSquare\u001b[0;34m(not_square)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msquare\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0mdoublesize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnot_square\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterpolation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mINTER_CUBIC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0mheight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mheight\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mwidth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwidth\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: ..\\..\\..\\modules\\imgproc\\src\\imgwarp.cpp:3229: error: (-215) ssize.area() > 0 in function cv::resize\n"
     ]
    }
   ],
   "source": [
    "nonfilledimage = cv2.imread('nonfilled_300.jpeg',0)\n",
    "#nonfilledimage = cv2.bitwise_not(nonfilledimage)\n",
    "nonfilledimage = cv2.threshold(nonfilledimage, 100, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "nonfilledimagedilated = nonfilledimage.copy()\n",
    "nonfilledimagedilated = cv2.dilate(nonfilledimagedilated, np.ones((2, 2), np.uint8), iterations=1)\n",
    "\n",
    "cv2.imshow('Non Filled', nonfilledimage)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "filledimage = cv2.imread('filled_300.jpeg',0)\n",
    "#filledimage = cv2.bitwise_not(filledimage)\n",
    "filledimage = cv2.threshold(filledimage, 100, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "#filledimage = cv2.erode(filledimage, np.ones((1, 1), np.uint8), iterations=1)\n",
    "cv2.imshow('Filled', filledimage)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "coordinates = [[201,326,1656,124],[201,981,2172,99],[925,3004,600,104],[191,1308,957,114]]\n",
    "\n",
    "label_dictionary = {0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '9', 10: 'a',\n",
    "                    11: 'b', 12: 'd', 13: 'e', 14: 'f', 15: 'g', 16: 'h', 17: 'i', 18: 'j', 19: 'l', 20: 'm',\n",
    "                    21: 'n', 22: 'q', 23: 'r', 24: 't', 25: 'y', 26: 'A', 27: 'B', 28: 'C', 29: 'D', 30: 'E',\n",
    "                    31: 'F', 32: 'G', 33: 'H', 34: 'I', 35: 'J', 36: 'K', 37: 'L', 38: 'M', 39: 'N', 40: 'O',\n",
    "                    41: 'P', 42: 'Q', 43: 'R', 44: 'S', 45: 'T', 46: 'U', 47: 'V', 48: 'W', 49: 'X', 50: 'Y',\n",
    "                    51: 'Z'}\n",
    "getNonfilledCroppedSections(coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '9', 10: 'a', 11: 'b', 12: 'd', 13: 'e', 14: 'f', 15: 'g', 16: 'h', 17: 'i', 18: 'j', 19: 'l', 20: 'm', 21: 'n', 22: 'q', 23: 'r', 24: 't', 25: 'y', 26: 'A', 27: 'B', 28: 'C', 29: 'D', 30: 'E', 31: 'F', 32: 'G', 33: 'H', 34: 'I', 35: 'J', 36: 'K', 37: 'L', 38: 'M', 39: 'N', 40: 'O', 41: 'P', 42: 'Q', 43: 'R', 44: 'S', 45: 'T', 46: 'U', 47: 'V', 48: 'W', 49: 'X', 50: 'Y', 51: 'Z'}\n"
     ]
    }
   ],
   "source": [
    "label_dictionary = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'b', 'd', 'e', 'f',\n",
    "                    'g', 'h', 'i', 'j', 'l', 'm', 'n', 'q', 'r', 't', 'y', 'A', 'B', 'C', 'D',\n",
    "                    'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q',\n",
    "                    'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n",
    "labels = {}\n",
    "i = 0\n",
    "for label in label_dictionary:\n",
    "    labels[i] = label\n",
    "    i = i + 1\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
